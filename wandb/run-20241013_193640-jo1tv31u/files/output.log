(1143, 6)
(1143, 11)
Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Layer: [in:11] [out:8] [activation:ReLU]
Layer: [in:8] [out:16] [activation:ReLU]
Layer: [in:16] [out:16] [activation:ReLU]
Layer: [in:16] [out:8] [activation:ReLU]
Layer: [in:8] [out:6] [activation:Softmax]
Training:  60%|██████████████████████████████████████████████████████████████████████▉                                               | 601/1000 [00:24<00:16, 24.63epoch/s, Train Acc=0.798, Val Acc=0.562]

Epoch: 0 	Train:[Loss: 1.3453, Acc: 0.3996] 	Val:[Loss: 1.2880, Acc: 0.4375]
Epoch: 100 	Train:[Loss: 0.7234, Acc: 0.7020] 	Val:[Loss: 1.0540, Acc: 0.5938]
Epoch: 200 	Train:[Loss: 0.6280, Acc: 0.7243] 	Val:[Loss: 1.2442, Acc: 0.6042]
Epoch: 300 	Train:[Loss: 0.5304, Acc: 0.7723] 	Val:[Loss: 1.5431, Acc: 0.6250]
Epoch: 400 	Train:[Loss: 0.6157, Acc: 0.7299] 	Val:[Loss: 1.7383, Acc: 0.5104]
Epoch: 500 	Train:[Loss: 0.5246, Acc: 0.7879] 	Val:[Loss: 1.8493, Acc: 0.5521]
Epoch: 600 	Train:[Loss: 0.5146, Acc: 0.7980] 	Val:[Loss: 1.9301, Acc: 0.5625]
Early stopping triggered at epoch 601.
Model weights restored to epoch 89.
best validation loss::0.9474918722547055
================Test set metrics======================

accuracy ::  0.8845029239766082
precision ::  0.40655968468468473
recall ::  0.3336285741792625
F1-score ::  0.36650116047045717

======================================================
