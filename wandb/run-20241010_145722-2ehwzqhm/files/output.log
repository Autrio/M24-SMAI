Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Training:   0%|                                                                                                                                                                 | 0/1000 [00:00<?, ?epoch/s]/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:254: RuntimeWarning: divide by zero encountered in log
  return np.mean(np.sum(-y  * np.log(y_pred), axis=-1))
/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:254: RuntimeWarning: invalid value encountered in multiply
  return np.mean(np.sum(-y  * np.log(y_pred), axis=-1))
/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:309: RuntimeWarning: overflow encountered in matmul
  z = x @ self.W.T + self.b
/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:309: RuntimeWarning: invalid value encountered in matmul
  z = x @ self.W.T + self.b
                                                                                                                                                                                                            
Epoch: 0 	Train:[Loss: nan, Acc: 0.0804] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 16 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 32 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 48 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 64 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 80 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 96 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 112 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 128 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 144 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 160 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 176 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 192 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 208 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 224 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 240 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 256 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 272 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 288 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 304 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 320 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 336 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 352 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 368 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 384 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 400 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 416 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 432 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 448 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 464 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 480 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 496 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 512 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 528 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 544 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 560 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 576 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 592 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 608 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 624 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 640 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 656 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 672 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 688 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 704 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 720 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 736 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 752 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 768 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 784 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 800 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 816 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 832 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 848 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 864 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 880 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 896 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 912 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 928 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 944 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 960 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 976 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 992 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
