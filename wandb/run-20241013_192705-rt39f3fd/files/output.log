(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
{'lr': 0.09315812840249442, 'batch_size': 64, 'epoch': 5000, 'optimizer': 'mini-batch', 'loss_fn': 'MSELoss', 'activation': 'Tanh', 'type': 'regression', 'early_stopping': True, 'activations': 'Tanh', 'model_architecture': 'arch5'}
Layer: [in:13] [out:16] [activation:Tanh]
Layer: [in:16] [out:64] [activation:Tanh]
Layer: [in:64] [out:128] [activation:Tanh]
Layer: [in:128] [out:256] [activation:Tanh]
Layer: [in:256] [out:1] [activation:Linear]
Training:  28%|████████████████████████████████▏                                                                                    | 1378/5000 [01:57<05:08, 11.73epoch/s, Train Acc=0.983, Val Acc=0.884]

Epoch: 0 	Train:[Loss: 616.4990, Acc: -5.8381] 	Val:[Loss: 559.5157, Acc: -5.3233]
Epoch: 100 	Train:[Loss: 17.8138, Acc: 0.8024] 	Val:[Loss: 23.5287, Acc: 0.7341]
Epoch: 200 	Train:[Loss: 9.9775, Acc: 0.8893] 	Val:[Loss: 16.0092, Acc: 0.8191]
Epoch: 300 	Train:[Loss: 6.9944, Acc: 0.9224] 	Val:[Loss: 12.8648, Acc: 0.8546]
Epoch: 400 	Train:[Loss: 5.4747, Acc: 0.9393] 	Val:[Loss: 11.5871, Acc: 0.8690]
Epoch: 500 	Train:[Loss: 4.4907, Acc: 0.9502] 	Val:[Loss: 10.9224, Acc: 0.8766]
Epoch: 600 	Train:[Loss: 3.7714, Acc: 0.9582] 	Val:[Loss: 10.5188, Acc: 0.8811]
Epoch: 700 	Train:[Loss: 3.2189, Acc: 0.9643] 	Val:[Loss: 10.2551, Acc: 0.8841]
Epoch: 800 	Train:[Loss: 2.7861, Acc: 0.9691] 	Val:[Loss: 10.0797, Acc: 0.8861]
Epoch: 900 	Train:[Loss: 2.5454, Acc: 0.9718] 	Val:[Loss: 10.2762, Acc: 0.8839]
Epoch: 1000 	Train:[Loss: 2.1884, Acc: 0.9757] 	Val:[Loss: 10.0118, Acc: 0.8869]
Epoch: 1100 	Train:[Loss: 2.9429, Acc: 0.9674] 	Val:[Loss: 11.8324, Acc: 0.8663]
Epoch: 1200 	Train:[Loss: 1.7954, Acc: 0.9801] 	Val:[Loss: 10.1835, Acc: 0.8849]
Epoch: 1300 	Train:[Loss: 1.7934, Acc: 0.9801] 	Val:[Loss: 10.6442, Acc: 0.8797]
Early stopping triggered at epoch 1378.
Model weights restored to epoch 866.
best validation loss::9.905836416651997
