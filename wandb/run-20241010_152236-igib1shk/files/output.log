Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Layer: [in:11] [out:32] [activation:Softmax]
Layer: [in:32] [out:128] [activation:Softmax]
Layer: [in:128] [out:128] [activation:Softmax]
Layer: [in:128] [out:32] [activation:Softmax]
Layer: [in:32] [out:6] [activation:Softmax]
                                                                                                                                                                                                            

Epoch: 0 	Train:[Loss: 0.1222, Acc: 0.3248] 	Val:[Loss: 0.1151, Acc: 0.3958]
Epoch: 16 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 32 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 48 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 64 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 80 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 96 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 112 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 128 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 144 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 160 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 176 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 192 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 208 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 224 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 240 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 256 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 272 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 288 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 304 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 320 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 336 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 352 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 368 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 384 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 400 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 416 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 432 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 448 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 464 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 480 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 496 	Train:[Loss: 0.1075, Acc: 0.4297] 	Val:[Loss: 0.1059, Acc: 0.4479]
Epoch: 512 	Train:[Loss: 0.1075, Acc: 0.4319] 	Val:[Loss: 0.1058, Acc: 0.4479]
Epoch: 528 	Train:[Loss: 0.1075, Acc: 0.4319] 	Val:[Loss: 0.1058, Acc: 0.4479]
Epoch: 544 	Train:[Loss: 0.1075, Acc: 0.4319] 	Val:[Loss: 0.1058, Acc: 0.4479]
Epoch: 560 	Train:[Loss: 0.1075, Acc: 0.4319] 	Val:[Loss: 0.1058, Acc: 0.4479]
Epoch: 576 	Train:[Loss: 0.1075, Acc: 0.4319] 	Val:[Loss: 0.1057, Acc: 0.4479]
Epoch: 592 	Train:[Loss: 0.1075, Acc: 0.4319] 	Val:[Loss: 0.1057, Acc: 0.4479]
Epoch: 608 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1057, Acc: 0.4479]
Epoch: 624 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1057, Acc: 0.4479]
Epoch: 640 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1057, Acc: 0.4479]
Epoch: 656 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1056, Acc: 0.4479]
Epoch: 672 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1056, Acc: 0.4479]
Epoch: 688 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1056, Acc: 0.4479]
Epoch: 704 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1056, Acc: 0.4479]
Epoch: 720 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1056, Acc: 0.4479]
Epoch: 736 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1055, Acc: 0.4479]
Epoch: 752 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1055, Acc: 0.4479]
Epoch: 768 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1055, Acc: 0.4479]
Epoch: 784 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1055, Acc: 0.4479]
Epoch: 800 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1055, Acc: 0.4479]
Epoch: 816 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1055, Acc: 0.4479]
Epoch: 832 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 848 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 864 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 880 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 896 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 912 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 928 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 944 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 960 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 976 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 992 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1008 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1024 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1040 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1056 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1072 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1088 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1104 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1054, Acc: 0.4479]
Epoch: 1120 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1136 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1152 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1168 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1184 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1200 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1216 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1232 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1248 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1264 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1280 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1296 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1312 	Train:[Loss: 0.1074, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1328 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1344 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1360 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1376 	Train:[Loss: 0.1073, Acc: 0.4319] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1392 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1408 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1424 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1440 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1456 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1472 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1488 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1504 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1520 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1536 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1552 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1568 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1584 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1600 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1616 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1632 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1648 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1664 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1680 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1696 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1712 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1728 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1744 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1760 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1776 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1792 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1808 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1824 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1840 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1856 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1872 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1888 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1904 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1920 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1936 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1952 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1053, Acc: 0.4479]
Epoch: 1968 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 1984 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2000 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2016 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2032 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2048 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2064 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2080 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2096 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2112 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2128 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2144 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2160 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2176 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2192 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2208 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2224 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2240 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2256 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2272 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2288 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2304 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2320 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2336 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2352 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2368 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2384 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2400 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2416 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2432 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2448 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2464 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2480 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2496 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2512 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2528 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2544 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2560 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2576 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2592 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2608 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2624 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2640 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2656 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2672 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2688 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2704 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2720 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2736 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2752 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2768 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2784 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2800 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2816 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2832 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2848 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2864 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2880 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2896 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2912 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2928 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2944 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2960 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2976 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 2992 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3008 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3024 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3040 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3056 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3072 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3088 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3104 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3120 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3136 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3152 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3168 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3184 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3200 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3216 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3232 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3248 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3264 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3280 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3296 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3312 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3328 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3344 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3360 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3376 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3392 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3408 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3424 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3440 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3456 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3472 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3488 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3504 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3520 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3536 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3552 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3568 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3584 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3600 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3616 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3632 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3648 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3664 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3680 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3696 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3712 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3728 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3744 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3760 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3776 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3792 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3808 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3824 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3840 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3856 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3872 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3888 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3904 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3920 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3936 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3952 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3968 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
Epoch: 3984 	Train:[Loss: 0.1074, Acc: 0.4308] 	Val:[Loss: 0.1052, Acc: 0.4479]
