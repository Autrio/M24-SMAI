(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
Layer: [in:13] [out:8] [activation:Tanh]
Layer: [in:8] [out:16] [activation:Tanh]
Layer: [in:16] [out:16] [activation:Tanh]
Layer: [in:16] [out:8] [activation:Tanh]
Layer: [in:8] [out:1] [activation:Linear]
Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:11<00:00, 348.49epoch/s, Train Acc=0.887, Val Acc=0.89]

Epoch: 0 	Train:[Loss: 628.4024, Acc: -6.1794] 	Val:[Loss: 606.0273, Acc: -5.8489]
Epoch: 400 	Train:[Loss: 83.6716, Acc: 0.0449] 	Val:[Loss: 75.9331, Acc: 0.1419]
Epoch: 800 	Train:[Loss: 55.0006, Acc: 0.3721] 	Val:[Loss: 49.1018, Acc: 0.4451]
Epoch: 1200 	Train:[Loss: 42.1315, Acc: 0.5199] 	Val:[Loss: 35.6306, Acc: 0.5973]
Epoch: 1600 	Train:[Loss: 30.5406, Acc: 0.6521] 	Val:[Loss: 23.6566, Acc: 0.7326]
Epoch: 2000 	Train:[Loss: 23.1239, Acc: 0.7366] 	Val:[Loss: 19.2359, Acc: 0.7826]
Epoch: 2400 	Train:[Loss: 18.4464, Acc: 0.7898] 	Val:[Loss: 16.4066, Acc: 0.8146]
Epoch: 2800 	Train:[Loss: 15.4567, Acc: 0.8238] 	Val:[Loss: 13.6217, Acc: 0.8461]
Epoch: 3200 	Train:[Loss: 13.1183, Acc: 0.8505] 	Val:[Loss: 12.0088, Acc: 0.8643]
Epoch: 3600 	Train:[Loss: 11.3477, Acc: 0.8707] 	Val:[Loss: 10.8412, Acc: 0.8775]
Epoch: 3999 	Train:[Loss: 9.9369, Acc: 0.8867] 	Val:[Loss: 9.7252, Acc: 0.8901]
32.4
[[35.93999402]]
