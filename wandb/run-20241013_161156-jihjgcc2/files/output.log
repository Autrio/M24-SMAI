(1143, 6)
(1143, 11)
Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
(11,)
                                                                                                                                                                                                            
Epoch: 0 	Train:[Loss: 0.1474, Acc: 0.1641] 	Val:[Loss: 0.1465, Acc: 0.1667]
Epoch: 10 	Train:[Loss: 0.1223, Acc: 0.3783] 	Val:[Loss: 0.1210, Acc: 0.4375]
Epoch: 20 	Train:[Loss: 0.1089, Acc: 0.5033] 	Val:[Loss: 0.1083, Acc: 0.5625]
Epoch: 30 	Train:[Loss: 0.1027, Acc: 0.5257] 	Val:[Loss: 0.1032, Acc: 0.5000]
Epoch: 40 	Train:[Loss: 0.0996, Acc: 0.5290] 	Val:[Loss: 0.1005, Acc: 0.4896]
Epoch: 50 	Train:[Loss: 0.0977, Acc: 0.5435] 	Val:[Loss: 0.0984, Acc: 0.5104]
Epoch: 60 	Train:[Loss: 0.0961, Acc: 0.5592] 	Val:[Loss: 0.0963, Acc: 0.5312]
Epoch: 70 	Train:[Loss: 0.0947, Acc: 0.5714] 	Val:[Loss: 0.0945, Acc: 0.5312]
Epoch: 80 	Train:[Loss: 0.0936, Acc: 0.5725] 	Val:[Loss: 0.0928, Acc: 0.5521]
Epoch: 90 	Train:[Loss: 0.0926, Acc: 0.5737] 	Val:[Loss: 0.0913, Acc: 0.5938]
Epoch: 100 	Train:[Loss: 0.0917, Acc: 0.5815] 	Val:[Loss: 0.0900, Acc: 0.5938]
Epoch: 110 	Train:[Loss: 0.0909, Acc: 0.5938] 	Val:[Loss: 0.0888, Acc: 0.6250]
Epoch: 120 	Train:[Loss: 0.0901, Acc: 0.5949] 	Val:[Loss: 0.0878, Acc: 0.6458]
Epoch: 130 	Train:[Loss: 0.0895, Acc: 0.6027] 	Val:[Loss: 0.0868, Acc: 0.6458]
Epoch: 140 	Train:[Loss: 0.0889, Acc: 0.6038] 	Val:[Loss: 0.0860, Acc: 0.6458]
Epoch: 150 	Train:[Loss: 0.0884, Acc: 0.6049] 	Val:[Loss: 0.0852, Acc: 0.6458]
Epoch: 160 	Train:[Loss: 0.0879, Acc: 0.6083] 	Val:[Loss: 0.0845, Acc: 0.6458]
Epoch: 170 	Train:[Loss: 0.0875, Acc: 0.6116] 	Val:[Loss: 0.0839, Acc: 0.6562]
Epoch: 180 	Train:[Loss: 0.0871, Acc: 0.6161] 	Val:[Loss: 0.0833, Acc: 0.6562]
Epoch: 190 	Train:[Loss: 0.0867, Acc: 0.6183] 	Val:[Loss: 0.0828, Acc: 0.6562]
Epoch: 200 	Train:[Loss: 0.0864, Acc: 0.6250] 	Val:[Loss: 0.0824, Acc: 0.6562]
Epoch: 210 	Train:[Loss: 0.0861, Acc: 0.6250] 	Val:[Loss: 0.0819, Acc: 0.6667]
Epoch: 220 	Train:[Loss: 0.0858, Acc: 0.6261] 	Val:[Loss: 0.0815, Acc: 0.6667]
Epoch: 230 	Train:[Loss: 0.0855, Acc: 0.6283] 	Val:[Loss: 0.0811, Acc: 0.6771]
Epoch: 240 	Train:[Loss: 0.0852, Acc: 0.6306] 	Val:[Loss: 0.0808, Acc: 0.6771]
Epoch: 250 	Train:[Loss: 0.0850, Acc: 0.6295] 	Val:[Loss: 0.0804, Acc: 0.6771]
Epoch: 260 	Train:[Loss: 0.0847, Acc: 0.6306] 	Val:[Loss: 0.0801, Acc: 0.6771]
Epoch: 270 	Train:[Loss: 0.0845, Acc: 0.6317] 	Val:[Loss: 0.0798, Acc: 0.6875]
Epoch: 280 	Train:[Loss: 0.0842, Acc: 0.6362] 	Val:[Loss: 0.0794, Acc: 0.6875]
Epoch: 290 	Train:[Loss: 0.0840, Acc: 0.6373] 	Val:[Loss: 0.0791, Acc: 0.6875]
Epoch: 300 	Train:[Loss: 0.0838, Acc: 0.6384] 	Val:[Loss: 0.0789, Acc: 0.6875]
Epoch: 310 	Train:[Loss: 0.0836, Acc: 0.6395] 	Val:[Loss: 0.0786, Acc: 0.6875]
Epoch: 320 	Train:[Loss: 0.0833, Acc: 0.6406] 	Val:[Loss: 0.0783, Acc: 0.6875]
Epoch: 330 	Train:[Loss: 0.0831, Acc: 0.6429] 	Val:[Loss: 0.0780, Acc: 0.6875]
Epoch: 340 	Train:[Loss: 0.0829, Acc: 0.6429] 	Val:[Loss: 0.0778, Acc: 0.6875]
Epoch: 350 	Train:[Loss: 0.0827, Acc: 0.6417] 	Val:[Loss: 0.0775, Acc: 0.6875]
Epoch: 360 	Train:[Loss: 0.0825, Acc: 0.6429] 	Val:[Loss: 0.0773, Acc: 0.6875]
Epoch: 370 	Train:[Loss: 0.0822, Acc: 0.6440] 	Val:[Loss: 0.0770, Acc: 0.6979]
Epoch: 380 	Train:[Loss: 0.0820, Acc: 0.6440] 	Val:[Loss: 0.0767, Acc: 0.6979]
Epoch: 390 	Train:[Loss: 0.0818, Acc: 0.6451] 	Val:[Loss: 0.0765, Acc: 0.6979]
Epoch: 400 	Train:[Loss: 0.0816, Acc: 0.6451] 	Val:[Loss: 0.0762, Acc: 0.6979]
Epoch: 410 	Train:[Loss: 0.0814, Acc: 0.6451] 	Val:[Loss: 0.0759, Acc: 0.6979]
Epoch: 420 	Train:[Loss: 0.0812, Acc: 0.6440] 	Val:[Loss: 0.0756, Acc: 0.7083]
Epoch: 430 	Train:[Loss: 0.0810, Acc: 0.6462] 	Val:[Loss: 0.0754, Acc: 0.7083]
Epoch: 440 	Train:[Loss: 0.0808, Acc: 0.6473] 	Val:[Loss: 0.0753, Acc: 0.7083]
Epoch: 450 	Train:[Loss: 0.0806, Acc: 0.6484] 	Val:[Loss: 0.0751, Acc: 0.7083]
Epoch: 460 	Train:[Loss: 0.0804, Acc: 0.6529] 	Val:[Loss: 0.0750, Acc: 0.7083]
Epoch: 470 	Train:[Loss: 0.0802, Acc: 0.6562] 	Val:[Loss: 0.0749, Acc: 0.7083]
Epoch: 480 	Train:[Loss: 0.0800, Acc: 0.6562] 	Val:[Loss: 0.0748, Acc: 0.6979]
Epoch: 490 	Train:[Loss: 0.0798, Acc: 0.6551] 	Val:[Loss: 0.0747, Acc: 0.6979]
Epoch: 500 	Train:[Loss: 0.0797, Acc: 0.6540] 	Val:[Loss: 0.0746, Acc: 0.6979]
Epoch: 510 	Train:[Loss: 0.0795, Acc: 0.6551] 	Val:[Loss: 0.0745, Acc: 0.6979]
Epoch: 520 	Train:[Loss: 0.0793, Acc: 0.6574] 	Val:[Loss: 0.0744, Acc: 0.6979]
Epoch: 530 	Train:[Loss: 0.0791, Acc: 0.6574] 	Val:[Loss: 0.0744, Acc: 0.6979]
Epoch: 540 	Train:[Loss: 0.0789, Acc: 0.6596] 	Val:[Loss: 0.0743, Acc: 0.7083]
Epoch: 550 	Train:[Loss: 0.0787, Acc: 0.6596] 	Val:[Loss: 0.0742, Acc: 0.7083]
Epoch: 560 	Train:[Loss: 0.0785, Acc: 0.6585] 	Val:[Loss: 0.0742, Acc: 0.7083]
Epoch: 570 	Train:[Loss: 0.0784, Acc: 0.6607] 	Val:[Loss: 0.0741, Acc: 0.7188]
Epoch: 580 	Train:[Loss: 0.0782, Acc: 0.6607] 	Val:[Loss: 0.0741, Acc: 0.7188]
Epoch: 590 	Train:[Loss: 0.0780, Acc: 0.6585] 	Val:[Loss: 0.0740, Acc: 0.7188]
Epoch: 600 	Train:[Loss: 0.0778, Acc: 0.6596] 	Val:[Loss: 0.0740, Acc: 0.7083]
Epoch: 610 	Train:[Loss: 0.0776, Acc: 0.6596] 	Val:[Loss: 0.0739, Acc: 0.7083]
Epoch: 620 	Train:[Loss: 0.0774, Acc: 0.6596] 	Val:[Loss: 0.0739, Acc: 0.7083]
Epoch: 630 	Train:[Loss: 0.0773, Acc: 0.6618] 	Val:[Loss: 0.0738, Acc: 0.7083]
Epoch: 640 	Train:[Loss: 0.0771, Acc: 0.6629] 	Val:[Loss: 0.0738, Acc: 0.7083]
Epoch: 650 	Train:[Loss: 0.0769, Acc: 0.6641] 	Val:[Loss: 0.0737, Acc: 0.7083]
Epoch: 660 	Train:[Loss: 0.0767, Acc: 0.6663] 	Val:[Loss: 0.0737, Acc: 0.7083]
Epoch: 670 	Train:[Loss: 0.0765, Acc: 0.6663] 	Val:[Loss: 0.0737, Acc: 0.7083]
Epoch: 680 	Train:[Loss: 0.0763, Acc: 0.6663] 	Val:[Loss: 0.0737, Acc: 0.7083]
Epoch: 690 	Train:[Loss: 0.0761, Acc: 0.6696] 	Val:[Loss: 0.0736, Acc: 0.7083]
Epoch: 700 	Train:[Loss: 0.0760, Acc: 0.6674] 	Val:[Loss: 0.0736, Acc: 0.7083]
Epoch: 710 	Train:[Loss: 0.0758, Acc: 0.6696] 	Val:[Loss: 0.0736, Acc: 0.7188]
Epoch: 720 	Train:[Loss: 0.0756, Acc: 0.6741] 	Val:[Loss: 0.0736, Acc: 0.7188]
Epoch: 730 	Train:[Loss: 0.0754, Acc: 0.6741] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 740 	Train:[Loss: 0.0752, Acc: 0.6752] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 750 	Train:[Loss: 0.0750, Acc: 0.6775] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 760 	Train:[Loss: 0.0749, Acc: 0.6819] 	Val:[Loss: 0.0735, Acc: 0.7188]
Epoch: 770 	Train:[Loss: 0.0747, Acc: 0.6830] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 780 	Train:[Loss: 0.0745, Acc: 0.6864] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 790 	Train:[Loss: 0.0743, Acc: 0.6864] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 800 	Train:[Loss: 0.0741, Acc: 0.6897] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 810 	Train:[Loss: 0.0740, Acc: 0.6920] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 820 	Train:[Loss: 0.0738, Acc: 0.6908] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 830 	Train:[Loss: 0.0736, Acc: 0.6931] 	Val:[Loss: 0.0735, Acc: 0.7083]
Epoch: 840 	Train:[Loss: 0.0734, Acc: 0.6908] 	Val:[Loss: 0.0736, Acc: 0.7083]
Epoch: 850 	Train:[Loss: 0.0733, Acc: 0.6920] 	Val:[Loss: 0.0736, Acc: 0.7083]
Epoch: 860 	Train:[Loss: 0.0731, Acc: 0.6931] 	Val:[Loss: 0.0736, Acc: 0.7083]
Epoch: 870 	Train:[Loss: 0.0729, Acc: 0.6942] 	Val:[Loss: 0.0737, Acc: 0.7083]
Epoch: 880 	Train:[Loss: 0.0727, Acc: 0.6931] 	Val:[Loss: 0.0737, Acc: 0.7083]
Epoch: 890 	Train:[Loss: 0.0726, Acc: 0.6953] 	Val:[Loss: 0.0738, Acc: 0.7083]
Epoch: 900 	Train:[Loss: 0.0724, Acc: 0.6964] 	Val:[Loss: 0.0738, Acc: 0.7083]
Epoch: 910 	Train:[Loss: 0.0722, Acc: 0.6953] 	Val:[Loss: 0.0739, Acc: 0.7083]
Epoch: 920 	Train:[Loss: 0.0720, Acc: 0.6953] 	Val:[Loss: 0.0739, Acc: 0.6979]
Epoch: 930 	Train:[Loss: 0.0719, Acc: 0.6942] 	Val:[Loss: 0.0740, Acc: 0.6979]
Epoch: 940 	Train:[Loss: 0.0717, Acc: 0.6953] 	Val:[Loss: 0.0741, Acc: 0.6979]
Epoch: 950 	Train:[Loss: 0.0715, Acc: 0.6942] 	Val:[Loss: 0.0742, Acc: 0.6979]
Epoch: 960 	Train:[Loss: 0.0713, Acc: 0.6953] 	Val:[Loss: 0.0743, Acc: 0.6979]
Epoch: 970 	Train:[Loss: 0.0712, Acc: 0.6975] 	Val:[Loss: 0.0744, Acc: 0.6875]
Epoch: 980 	Train:[Loss: 0.0710, Acc: 0.6998] 	Val:[Loss: 0.0745, Acc: 0.6875]
Epoch: 990 	Train:[Loss: 0.0708, Acc: 0.6987] 	Val:[Loss: 0.0745, Acc: 0.6875]
Epoch: 1000 	Train:[Loss: 0.0706, Acc: 0.6975] 	Val:[Loss: 0.0746, Acc: 0.6875]
Epoch: 1010 	Train:[Loss: 0.0704, Acc: 0.6998] 	Val:[Loss: 0.0747, Acc: 0.6771]
Epoch: 1020 	Train:[Loss: 0.0703, Acc: 0.7020] 	Val:[Loss: 0.0749, Acc: 0.6771]
Epoch: 1030 	Train:[Loss: 0.0701, Acc: 0.7076] 	Val:[Loss: 0.0750, Acc: 0.6771]
Epoch: 1040 	Train:[Loss: 0.0699, Acc: 0.7076] 	Val:[Loss: 0.0751, Acc: 0.6771]
Epoch: 1050 	Train:[Loss: 0.0697, Acc: 0.7098] 	Val:[Loss: 0.0752, Acc: 0.6771]
Epoch: 1060 	Train:[Loss: 0.0695, Acc: 0.7109] 	Val:[Loss: 0.0754, Acc: 0.6771]
Epoch: 1070 	Train:[Loss: 0.0693, Acc: 0.7143] 	Val:[Loss: 0.0756, Acc: 0.6771]
Epoch: 1080 	Train:[Loss: 0.0691, Acc: 0.7165] 	Val:[Loss: 0.0758, Acc: 0.6771]
Epoch: 1090 	Train:[Loss: 0.0690, Acc: 0.7154] 	Val:[Loss: 0.0760, Acc: 0.6667]
Epoch: 1100 	Train:[Loss: 0.0688, Acc: 0.7165] 	Val:[Loss: 0.0761, Acc: 0.6667]
Epoch: 1110 	Train:[Loss: 0.0686, Acc: 0.7165] 	Val:[Loss: 0.0763, Acc: 0.6667]
Epoch: 1120 	Train:[Loss: 0.0684, Acc: 0.7188] 	Val:[Loss: 0.0765, Acc: 0.6667]
Epoch: 1130 	Train:[Loss: 0.0682, Acc: 0.7176] 	Val:[Loss: 0.0766, Acc: 0.6771]
Epoch: 1140 	Train:[Loss: 0.0680, Acc: 0.7210] 	Val:[Loss: 0.0768, Acc: 0.6771]
Epoch: 1150 	Train:[Loss: 0.0678, Acc: 0.7232] 	Val:[Loss: 0.0769, Acc: 0.6875]
Epoch: 1160 	Train:[Loss: 0.0677, Acc: 0.7232] 	Val:[Loss: 0.0771, Acc: 0.6875]
Epoch: 1170 	Train:[Loss: 0.0675, Acc: 0.7232] 	Val:[Loss: 0.0772, Acc: 0.6875]
Epoch: 1180 	Train:[Loss: 0.0673, Acc: 0.7243] 	Val:[Loss: 0.0774, Acc: 0.6875]
Epoch: 1190 	Train:[Loss: 0.0671, Acc: 0.7254] 	Val:[Loss: 0.0775, Acc: 0.6771]
Epoch: 1200 	Train:[Loss: 0.0669, Acc: 0.7277] 	Val:[Loss: 0.0776, Acc: 0.6771]
Epoch: 1210 	Train:[Loss: 0.0667, Acc: 0.7266] 	Val:[Loss: 0.0778, Acc: 0.6771]
Epoch: 1220 	Train:[Loss: 0.0665, Acc: 0.7277] 	Val:[Loss: 0.0779, Acc: 0.6667]
Epoch: 1230 	Train:[Loss: 0.0663, Acc: 0.7277] 	Val:[Loss: 0.0780, Acc: 0.6667]
Epoch: 1240 	Train:[Loss: 0.0661, Acc: 0.7299] 	Val:[Loss: 0.0782, Acc: 0.6667]
Epoch: 1250 	Train:[Loss: 0.0659, Acc: 0.7299] 	Val:[Loss: 0.0783, Acc: 0.6667]
Epoch: 1260 	Train:[Loss: 0.0657, Acc: 0.7321] 	Val:[Loss: 0.0784, Acc: 0.6771]
Epoch: 1270 	Train:[Loss: 0.0655, Acc: 0.7333] 	Val:[Loss: 0.0785, Acc: 0.6771]
Epoch: 1280 	Train:[Loss: 0.0653, Acc: 0.7344] 	Val:[Loss: 0.0787, Acc: 0.6771]
Epoch: 1290 	Train:[Loss: 0.0651, Acc: 0.7377] 	Val:[Loss: 0.0788, Acc: 0.6771]
Epoch: 1300 	Train:[Loss: 0.0649, Acc: 0.7377] 	Val:[Loss: 0.0789, Acc: 0.6771]
Epoch: 1310 	Train:[Loss: 0.0647, Acc: 0.7377] 	Val:[Loss: 0.0791, Acc: 0.6771]
Epoch: 1320 	Train:[Loss: 0.0645, Acc: 0.7388] 	Val:[Loss: 0.0792, Acc: 0.6771]
Epoch: 1330 	Train:[Loss: 0.0643, Acc: 0.7377] 	Val:[Loss: 0.0793, Acc: 0.6771]
Epoch: 1340 	Train:[Loss: 0.0641, Acc: 0.7388] 	Val:[Loss: 0.0795, Acc: 0.6875]
Epoch: 1350 	Train:[Loss: 0.0639, Acc: 0.7388] 	Val:[Loss: 0.0796, Acc: 0.6875]
Epoch: 1360 	Train:[Loss: 0.0637, Acc: 0.7388] 	Val:[Loss: 0.0797, Acc: 0.6875]
Epoch: 1370 	Train:[Loss: 0.0635, Acc: 0.7400] 	Val:[Loss: 0.0799, Acc: 0.6875]
Epoch: 1380 	Train:[Loss: 0.0633, Acc: 0.7411] 	Val:[Loss: 0.0800, Acc: 0.6875]
Epoch: 1390 	Train:[Loss: 0.0631, Acc: 0.7411] 	Val:[Loss: 0.0802, Acc: 0.6875]
Epoch: 1400 	Train:[Loss: 0.0629, Acc: 0.7411] 	Val:[Loss: 0.0803, Acc: 0.6875]
Epoch: 1410 	Train:[Loss: 0.0627, Acc: 0.7422] 	Val:[Loss: 0.0805, Acc: 0.6875]
Epoch: 1420 	Train:[Loss: 0.0625, Acc: 0.7422] 	Val:[Loss: 0.0807, Acc: 0.6875]
Epoch: 1430 	Train:[Loss: 0.0623, Acc: 0.7411] 	Val:[Loss: 0.0808, Acc: 0.6875]
Epoch: 1440 	Train:[Loss: 0.0621, Acc: 0.7400] 	Val:[Loss: 0.0810, Acc: 0.6771]
Epoch: 1450 	Train:[Loss: 0.0619, Acc: 0.7422] 	Val:[Loss: 0.0811, Acc: 0.6771]
Epoch: 1460 	Train:[Loss: 0.0617, Acc: 0.7411] 	Val:[Loss: 0.0813, Acc: 0.6771]
Epoch: 1470 	Train:[Loss: 0.0615, Acc: 0.7444] 	Val:[Loss: 0.0815, Acc: 0.6771]
Epoch: 1480 	Train:[Loss: 0.0613, Acc: 0.7467] 	Val:[Loss: 0.0817, Acc: 0.6771]
Epoch: 1490 	Train:[Loss: 0.0611, Acc: 0.7478] 	Val:[Loss: 0.0818, Acc: 0.6771]
Epoch: 1500 	Train:[Loss: 0.0610, Acc: 0.7500] 	Val:[Loss: 0.0820, Acc: 0.6771]
Epoch: 1510 	Train:[Loss: 0.0608, Acc: 0.7500] 	Val:[Loss: 0.0822, Acc: 0.6771]
Epoch: 1520 	Train:[Loss: 0.0606, Acc: 0.7511] 	Val:[Loss: 0.0823, Acc: 0.6771]
Epoch: 1530 	Train:[Loss: 0.0604, Acc: 0.7500] 	Val:[Loss: 0.0825, Acc: 0.6771]
Epoch: 1540 	Train:[Loss: 0.0602, Acc: 0.7500] 	Val:[Loss: 0.0827, Acc: 0.6771]
Epoch: 1550 	Train:[Loss: 0.0600, Acc: 0.7511] 	Val:[Loss: 0.0829, Acc: 0.6771]
Epoch: 1560 	Train:[Loss: 0.0598, Acc: 0.7533] 	Val:[Loss: 0.0830, Acc: 0.6771]
Epoch: 1570 	Train:[Loss: 0.0596, Acc: 0.7545] 	Val:[Loss: 0.0832, Acc: 0.6771]
Epoch: 1580 	Train:[Loss: 0.0594, Acc: 0.7567] 	Val:[Loss: 0.0834, Acc: 0.6771]
Epoch: 1590 	Train:[Loss: 0.0593, Acc: 0.7567] 	Val:[Loss: 0.0836, Acc: 0.6771]
Epoch: 1600 	Train:[Loss: 0.0591, Acc: 0.7578] 	Val:[Loss: 0.0837, Acc: 0.6771]
Epoch: 1610 	Train:[Loss: 0.0589, Acc: 0.7589] 	Val:[Loss: 0.0839, Acc: 0.6667]
Epoch: 1620 	Train:[Loss: 0.0587, Acc: 0.7600] 	Val:[Loss: 0.0841, Acc: 0.6667]
Epoch: 1630 	Train:[Loss: 0.0585, Acc: 0.7623] 	Val:[Loss: 0.0843, Acc: 0.6667]
Epoch: 1640 	Train:[Loss: 0.0583, Acc: 0.7645] 	Val:[Loss: 0.0844, Acc: 0.6667]
Epoch: 1650 	Train:[Loss: 0.0581, Acc: 0.7656] 	Val:[Loss: 0.0846, Acc: 0.6667]
Epoch: 1660 	Train:[Loss: 0.0579, Acc: 0.7667] 	Val:[Loss: 0.0848, Acc: 0.6667]
Epoch: 1670 	Train:[Loss: 0.0578, Acc: 0.7679] 	Val:[Loss: 0.0849, Acc: 0.6667]
Epoch: 1680 	Train:[Loss: 0.0576, Acc: 0.7667] 	Val:[Loss: 0.0851, Acc: 0.6458]
Epoch: 1690 	Train:[Loss: 0.0574, Acc: 0.7701] 	Val:[Loss: 0.0852, Acc: 0.6458]
Epoch: 1700 	Train:[Loss: 0.0572, Acc: 0.7690] 	Val:[Loss: 0.0854, Acc: 0.6458]
Epoch: 1710 	Train:[Loss: 0.0570, Acc: 0.7701] 	Val:[Loss: 0.0856, Acc: 0.6458]
Epoch: 1720 	Train:[Loss: 0.0568, Acc: 0.7701] 	Val:[Loss: 0.0857, Acc: 0.6458]
Epoch: 1730 	Train:[Loss: 0.0566, Acc: 0.7690] 	Val:[Loss: 0.0859, Acc: 0.6458]
Epoch: 1740 	Train:[Loss: 0.0564, Acc: 0.7712] 	Val:[Loss: 0.0860, Acc: 0.6458]
Epoch: 1750 	Train:[Loss: 0.0563, Acc: 0.7734] 	Val:[Loss: 0.0862, Acc: 0.6458]
Epoch: 1760 	Train:[Loss: 0.0561, Acc: 0.7746] 	Val:[Loss: 0.0863, Acc: 0.6250]
Epoch: 1770 	Train:[Loss: 0.0559, Acc: 0.7746] 	Val:[Loss: 0.0864, Acc: 0.6250]
Epoch: 1780 	Train:[Loss: 0.0557, Acc: 0.7746] 	Val:[Loss: 0.0866, Acc: 0.6250]
Epoch: 1790 	Train:[Loss: 0.0555, Acc: 0.7757] 	Val:[Loss: 0.0867, Acc: 0.6250]
Epoch: 1800 	Train:[Loss: 0.0553, Acc: 0.7790] 	Val:[Loss: 0.0868, Acc: 0.6250]
Early stopping triggered at epoch 1810.
Model weights restored to epoch 786.
best validation loss::0.07349134608091386
0.868421052631579
