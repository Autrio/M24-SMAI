(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
Layer: [in:13] [out:8] [activation:Sigmoid]
Layer: [in:8] [out:16] [activation:Sigmoid]
Layer: [in:16] [out:16] [activation:Sigmoid]
Layer: [in:16] [out:8] [activation:Sigmoid]
Layer: [in:8] [out:1] [activation:Linear]
Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:05<00:00, 382.88epoch/s, Train Acc=0.546, Val Acc=0.636]

Epoch: 0 	Train:[Loss: 670.4849, Acc: -6.4369] 	Val:[Loss: 639.7221, Acc: -6.2297]
Epoch: 100 	Train:[Loss: 164.8829, Acc: -0.8289] 	Val:[Loss: 153.7707, Acc: -0.7378]
Epoch: 200 	Train:[Loss: 93.8490, Acc: -0.0410] 	Val:[Loss: 90.5363, Acc: -0.0232]
Epoch: 300 	Train:[Loss: 90.1467, Acc: 0.0001] 	Val:[Loss: 88.2630, Acc: 0.0025]
Epoch: 400 	Train:[Loss: 89.9136, Acc: 0.0027] 	Val:[Loss: 88.3058, Acc: 0.0020]
Epoch: 500 	Train:[Loss: 89.8285, Acc: 0.0036] 	Val:[Loss: 88.2625, Acc: 0.0025]
Epoch: 600 	Train:[Loss: 89.7332, Acc: 0.0047] 	Val:[Loss: 88.1564, Acc: 0.0037]
Epoch: 700 	Train:[Loss: 89.6124, Acc: 0.0060] 	Val:[Loss: 88.0079, Acc: 0.0054]
Epoch: 800 	Train:[Loss: 89.4513, Acc: 0.0078] 	Val:[Loss: 87.8060, Acc: 0.0077]
Epoch: 900 	Train:[Loss: 89.2231, Acc: 0.0103] 	Val:[Loss: 87.5181, Acc: 0.0109]
Epoch: 1000 	Train:[Loss: 88.8735, Acc: 0.0142] 	Val:[Loss: 87.0742, Acc: 0.0159]
Epoch: 1100 	Train:[Loss: 88.2776, Acc: 0.0208] 	Val:[Loss: 86.3118, Acc: 0.0246]
Epoch: 1200 	Train:[Loss: 87.1194, Acc: 0.0337] 	Val:[Loss: 84.8201, Acc: 0.0414]
Epoch: 1300 	Train:[Loss: 84.7576, Acc: 0.0599] 	Val:[Loss: 81.8102, Acc: 0.0754]
Epoch: 1400 	Train:[Loss: 80.6566, Acc: 0.1054] 	Val:[Loss: 76.8464, Acc: 0.1315]
Epoch: 1500 	Train:[Loss: 74.4645, Acc: 0.1741] 	Val:[Loss: 69.6375, Acc: 0.2130]
Epoch: 1600 	Train:[Loss: 66.7682, Acc: 0.2594] 	Val:[Loss: 60.8023, Acc: 0.3129]
Epoch: 1700 	Train:[Loss: 59.1488, Acc: 0.3439] 	Val:[Loss: 52.1194, Acc: 0.4110]
Epoch: 1800 	Train:[Loss: 52.2715, Acc: 0.4202] 	Val:[Loss: 44.4195, Acc: 0.4980]
Epoch: 1900 	Train:[Loss: 46.0503, Acc: 0.4892] 	Val:[Loss: 37.6040, Acc: 0.5750]
Epoch: 1999 	Train:[Loss: 40.9599, Acc: 0.5457] 	Val:[Loss: 32.2143, Acc: 0.6359]
