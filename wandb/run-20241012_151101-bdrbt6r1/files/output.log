(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
Layer: [in:13] [out:16] [activation:ReLU]
Layer: [in:16] [out:64] [activation:ReLU]
Layer: [in:64] [out:128] [activation:ReLU]
Layer: [in:128] [out:256] [activation:ReLU]
Layer: [in:256] [out:1] [activation:Linear]
Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:37<00:00, 12.69epoch/s, Train Acc=0.969, Val Acc=0.902]

Epoch: 0 	Train:[Loss: 524.5571, Acc: -4.8183] 	Val:[Loss: 238.9810, Acc: -1.7008]
Epoch: 128 	Train:[Loss: 12.0511, Acc: 0.8663] 	Val:[Loss: 10.2177, Acc: 0.8845]
Epoch: 256 	Train:[Loss: 9.1724, Acc: 0.8983] 	Val:[Loss: 10.4381, Acc: 0.8820]
Epoch: 384 	Train:[Loss: 7.6452, Acc: 0.9152] 	Val:[Loss: 10.5104, Acc: 0.8812]
Epoch: 512 	Train:[Loss: 6.7169, Acc: 0.9255] 	Val:[Loss: 10.3593, Acc: 0.8829]
Epoch: 640 	Train:[Loss: 6.0321, Acc: 0.9331] 	Val:[Loss: 10.2840, Acc: 0.8838]
Epoch: 768 	Train:[Loss: 5.3426, Acc: 0.9407] 	Val:[Loss: 10.1998, Acc: 0.8847]
Epoch: 896 	Train:[Loss: 4.8543, Acc: 0.9462] 	Val:[Loss: 10.2576, Acc: 0.8841]
Epoch: 1024 	Train:[Loss: 4.2640, Acc: 0.9527] 	Val:[Loss: 10.0062, Acc: 0.8869]
Epoch: 1152 	Train:[Loss: 4.1870, Acc: 0.9536] 	Val:[Loss: 10.4792, Acc: 0.8816]
Epoch: 1280 	Train:[Loss: 3.8329, Acc: 0.9575] 	Val:[Loss: 10.4404, Acc: 0.8820]
Epoch: 1408 	Train:[Loss: 3.6356, Acc: 0.9597] 	Val:[Loss: 10.5122, Acc: 0.8812]
Epoch: 1536 	Train:[Loss: 3.4421, Acc: 0.9618] 	Val:[Loss: 10.6255, Acc: 0.8799]
Epoch: 1664 	Train:[Loss: 3.3446, Acc: 0.9629] 	Val:[Loss: 10.6925, Acc: 0.8792]
Epoch: 1792 	Train:[Loss: 2.9830, Acc: 0.9669] 	Val:[Loss: 10.4700, Acc: 0.8817]
Epoch: 1920 	Train:[Loss: 2.8436, Acc: 0.9685] 	Val:[Loss: 10.4985, Acc: 0.8814]
