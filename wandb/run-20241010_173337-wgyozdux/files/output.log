Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Layer: [in:11] [out:32] [activation:Tanh]
Layer: [in:32] [out:128] [activation:Tanh]
Layer: [in:128] [out:128] [activation:Tanh]
Layer: [in:128] [out:32] [activation:Tanh]
Layer: [in:32] [out:6] [activation:Softmax]
                                                                                                                                                                                                            

Epoch: 0 	Train:[Loss: 4.7144, Acc: 0.2667] 	Val:[Loss: 1.9893, Acc: 0.4688]
Epoch: 64 	Train:[Loss: 0.8931, Acc: 0.6417] 	Val:[Loss: 1.0613, Acc: 0.5833]
Epoch: 128 	Train:[Loss: 0.7586, Acc: 0.6641] 	Val:[Loss: 1.0264, Acc: 0.6146]
Epoch: 192 	Train:[Loss: 0.7266, Acc: 0.6786] 	Val:[Loss: 1.0023, Acc: 0.6458]
Epoch: 256 	Train:[Loss: 0.6236, Acc: 0.7411] 	Val:[Loss: 0.9818, Acc: 0.6354]
Epoch: 320 	Train:[Loss: 0.6008, Acc: 0.7422] 	Val:[Loss: 1.0732, Acc: 0.6354]
Epoch: 384 	Train:[Loss: 0.5761, Acc: 0.7489] 	Val:[Loss: 1.0030, Acc: 0.6354]
Epoch: 448 	Train:[Loss: 0.5503, Acc: 0.7589] 	Val:[Loss: 1.1667, Acc: 0.6354]
Epoch: 512 	Train:[Loss: 0.4850, Acc: 0.7991] 	Val:[Loss: 1.2176, Acc: 0.6042]
Epoch: 576 	Train:[Loss: 0.4493, Acc: 0.8237] 	Val:[Loss: 1.2101, Acc: 0.6562]
Epoch: 640 	Train:[Loss: 0.4362, Acc: 0.8304] 	Val:[Loss: 1.2805, Acc: 0.6250]
Epoch: 704 	Train:[Loss: 0.5568, Acc: 0.7634] 	Val:[Loss: 1.3181, Acc: 0.6458]
Epoch: 768 	Train:[Loss: 0.4714, Acc: 0.8181] 	Val:[Loss: 1.2298, Acc: 0.6042]
Epoch: 832 	Train:[Loss: 0.3790, Acc: 0.8549] 	Val:[Loss: 1.4447, Acc: 0.5729]
Epoch: 896 	Train:[Loss: 0.3363, Acc: 0.8661] 	Val:[Loss: 1.3998, Acc: 0.5625]
Epoch: 960 	Train:[Loss: 0.6407, Acc: 0.7522] 	Val:[Loss: 1.5609, Acc: 0.5729]
Epoch: 1024 	Train:[Loss: 0.3249, Acc: 0.8772] 	Val:[Loss: 1.4544, Acc: 0.6042]
Epoch: 1088 	Train:[Loss: 0.3344, Acc: 0.8616] 	Val:[Loss: 1.4949, Acc: 0.5938]
Epoch: 1152 	Train:[Loss: 0.3966, Acc: 0.8337] 	Val:[Loss: 1.4046, Acc: 0.6562]
Epoch: 1216 	Train:[Loss: 0.2986, Acc: 0.8895] 	Val:[Loss: 1.5745, Acc: 0.5833]
Epoch: 1280 	Train:[Loss: 0.2754, Acc: 0.9018] 	Val:[Loss: 1.6412, Acc: 0.6042]
Epoch: 1344 	Train:[Loss: 0.2716, Acc: 0.8962] 	Val:[Loss: 1.7894, Acc: 0.6042]
Epoch: 1408 	Train:[Loss: 0.2859, Acc: 0.8817] 	Val:[Loss: 1.6571, Acc: 0.5729]
Epoch: 1472 	Train:[Loss: 0.3522, Acc: 0.8638] 	Val:[Loss: 1.6450, Acc: 0.5833]
Epoch: 1536 	Train:[Loss: 0.2843, Acc: 0.8962] 	Val:[Loss: 1.6605, Acc: 0.6250]
Epoch: 1600 	Train:[Loss: 0.2613, Acc: 0.9007] 	Val:[Loss: 1.7608, Acc: 0.5729]
Epoch: 1664 	Train:[Loss: 0.2641, Acc: 0.8940] 	Val:[Loss: 1.8091, Acc: 0.5938]
Epoch: 1728 	Train:[Loss: 0.2650, Acc: 0.8996] 	Val:[Loss: 1.8531, Acc: 0.5833]
Epoch: 1792 	Train:[Loss: 0.2779, Acc: 0.8929] 	Val:[Loss: 1.8769, Acc: 0.5833]
Epoch: 1856 	Train:[Loss: 0.2779, Acc: 0.8850] 	Val:[Loss: 1.7827, Acc: 0.6667]
Epoch: 1920 	Train:[Loss: 0.3699, Acc: 0.8449] 	Val:[Loss: 1.8562, Acc: 0.5938]
Epoch: 1984 	Train:[Loss: 0.2067, Acc: 0.9241] 	Val:[Loss: 1.9166, Acc: 0.5625]
Epoch: 2048 	Train:[Loss: 0.3774, Acc: 0.8616] 	Val:[Loss: 1.9219, Acc: 0.6146]
Epoch: 2112 	Train:[Loss: 0.4254, Acc: 0.8281] 	Val:[Loss: 1.8127, Acc: 0.6354]
Epoch: 2176 	Train:[Loss: 0.3094, Acc: 0.8761] 	Val:[Loss: 1.9358, Acc: 0.6146]
Epoch: 2240 	Train:[Loss: 0.3294, Acc: 0.8638] 	Val:[Loss: 1.5714, Acc: 0.6042]
Epoch: 2304 	Train:[Loss: 0.3655, Acc: 0.8527] 	Val:[Loss: 1.9362, Acc: 0.5625]
Epoch: 2368 	Train:[Loss: 0.3025, Acc: 0.8862] 	Val:[Loss: 1.7652, Acc: 0.5729]
Epoch: 2432 	Train:[Loss: 0.1687, Acc: 0.9431] 	Val:[Loss: 1.8336, Acc: 0.5938]
Epoch: 2496 	Train:[Loss: 0.3066, Acc: 0.8817] 	Val:[Loss: 1.8969, Acc: 0.6354]
Epoch: 2560 	Train:[Loss: 0.1573, Acc: 0.9453] 	Val:[Loss: 1.8651, Acc: 0.5417]
Epoch: 2624 	Train:[Loss: 0.1472, Acc: 0.9554] 	Val:[Loss: 1.8598, Acc: 0.6146]
Epoch: 2688 	Train:[Loss: 0.3321, Acc: 0.8583] 	Val:[Loss: 1.6320, Acc: 0.5729]
Epoch: 2752 	Train:[Loss: 0.1750, Acc: 0.9453] 	Val:[Loss: 1.5890, Acc: 0.6250]
Epoch: 2816 	Train:[Loss: 0.1541, Acc: 0.9498] 	Val:[Loss: 1.9728, Acc: 0.6146]
Epoch: 2880 	Train:[Loss: 0.1386, Acc: 0.9520] 	Val:[Loss: 1.8912, Acc: 0.6146]
Epoch: 2944 	Train:[Loss: 0.8263, Acc: 0.7266] 	Val:[Loss: 1.7442, Acc: 0.6146]
Epoch: 3008 	Train:[Loss: 0.1494, Acc: 0.9542] 	Val:[Loss: 1.9737, Acc: 0.6146]
Epoch: 3072 	Train:[Loss: 0.1363, Acc: 0.9554] 	Val:[Loss: 2.0124, Acc: 0.5833]
Epoch: 3136 	Train:[Loss: 0.1269, Acc: 0.9632] 	Val:[Loss: 2.0793, Acc: 0.5833]
Epoch: 3200 	Train:[Loss: 0.1233, Acc: 0.9643] 	Val:[Loss: 2.0869, Acc: 0.5833]
Epoch: 3264 	Train:[Loss: 0.3066, Acc: 0.8850] 	Val:[Loss: 2.1651, Acc: 0.5833]
Epoch: 3328 	Train:[Loss: 0.1571, Acc: 0.9431] 	Val:[Loss: 2.0657, Acc: 0.6042]
Epoch: 3392 	Train:[Loss: 0.1087, Acc: 0.9710] 	Val:[Loss: 2.1331, Acc: 0.6042]
Epoch: 3456 	Train:[Loss: 0.1359, Acc: 0.9542] 	Val:[Loss: 2.1235, Acc: 0.6146]
Epoch: 3520 	Train:[Loss: 0.5115, Acc: 0.8415] 	Val:[Loss: 2.0913, Acc: 0.5938]
Epoch: 3584 	Train:[Loss: 0.3145, Acc: 0.8638] 	Val:[Loss: 1.9574, Acc: 0.6250]
Epoch: 3648 	Train:[Loss: 0.3387, Acc: 0.8717] 	Val:[Loss: 2.0160, Acc: 0.5833]
Epoch: 3712 	Train:[Loss: 0.0962, Acc: 0.9732] 	Val:[Loss: 2.1617, Acc: 0.5938]
Epoch: 3776 	Train:[Loss: 0.1364, Acc: 0.9598] 	Val:[Loss: 1.9950, Acc: 0.6146]
Epoch: 3840 	Train:[Loss: 0.1984, Acc: 0.9286] 	Val:[Loss: 2.0358, Acc: 0.6042]
Epoch: 3904 	Train:[Loss: 0.1001, Acc: 0.9732] 	Val:[Loss: 2.2218, Acc: 0.5938]
Epoch: 3968 	Train:[Loss: 0.0937, Acc: 0.9743] 	Val:[Loss: 2.1845, Acc: 0.5833]
