(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
{'lr': 0.07382884166389571, 'batch_size': 128, 'epoch': 5000, 'optimizer': 'mini-batch', 'loss_fn': 'MSELoss', 'activation': 'Tanh', 'type': 'regression', 'early_stopping': True, 'activations': 'Sigmoid', 'model_architecture': 'arch5'}
Layer: [in:13] [out:16] [activation:Sigmoid]
Layer: [in:16] [out:64] [activation:Sigmoid]
Layer: [in:64] [out:128] [activation:Sigmoid]
Layer: [in:128] [out:256] [activation:Sigmoid]
Layer: [in:256] [out:1] [activation:Linear]
                                                                                                                                                                                                           

Epoch: 0 	Train:[Loss: 602.2266, Acc: -5.6798] 	Val:[Loss: 429.6169, Acc: -3.8552]
Epoch: 100 	Train:[Loss: 89.4874, Acc: 0.0074] 	Val:[Loss: 87.7500, Acc: 0.0083]
Epoch: 200 	Train:[Loss: 88.7933, Acc: 0.0151] 	Val:[Loss: 86.8878, Acc: 0.0181]
Epoch: 300 	Train:[Loss: 87.8479, Acc: 0.0256] 	Val:[Loss: 85.7133, Acc: 0.0313]
Epoch: 400 	Train:[Loss: 86.4133, Acc: 0.0415] 	Val:[Loss: 83.9384, Acc: 0.0514]
Epoch: 500 	Train:[Loss: 84.0297, Acc: 0.0680] 	Val:[Loss: 81.0120, Acc: 0.0845]
Epoch: 600 	Train:[Loss: 79.7571, Acc: 0.1153] 	Val:[Loss: 75.8178, Acc: 0.1432]
Epoch: 700 	Train:[Loss: 71.8633, Acc: 0.2029] 	Val:[Loss: 66.3147, Acc: 0.2506]
Epoch: 800 	Train:[Loss: 59.0607, Acc: 0.3449] 	Val:[Loss: 50.9566, Acc: 0.4241]
Epoch: 900 	Train:[Loss: 45.6938, Acc: 0.4932] 	Val:[Loss: 34.7056, Acc: 0.6078]
Epoch: 1000 	Train:[Loss: 36.8125, Acc: 0.5917] 	Val:[Loss: 24.1130, Acc: 0.7275]
Epoch: 1100 	Train:[Loss: 30.5537, Acc: 0.6611] 	Val:[Loss: 17.9862, Acc: 0.7967]
Epoch: 1200 	Train:[Loss: 26.5405, Acc: 0.7056] 	Val:[Loss: 15.1419, Acc: 0.8289]
Epoch: 1300 	Train:[Loss: 24.2341, Acc: 0.7312] 	Val:[Loss: 13.9595, Acc: 0.8422]
Epoch: 1400 	Train:[Loss: 22.7474, Acc: 0.7477] 	Val:[Loss: 13.2639, Acc: 0.8501]
Epoch: 1500 	Train:[Loss: 21.6685, Acc: 0.7597] 	Val:[Loss: 12.7236, Acc: 0.8562]
Epoch: 1600 	Train:[Loss: 20.8167, Acc: 0.7691] 	Val:[Loss: 12.2671, Acc: 0.8614]
Epoch: 1700 	Train:[Loss: 20.1042, Acc: 0.7770] 	Val:[Loss: 11.8728, Acc: 0.8658]
Epoch: 1800 	Train:[Loss: 19.4825, Acc: 0.7839] 	Val:[Loss: 11.5238, Acc: 0.8698]
Epoch: 1900 	Train:[Loss: 18.9216, Acc: 0.7901] 	Val:[Loss: 11.2050, Acc: 0.8734]
Epoch: 2000 	Train:[Loss: 18.4015, Acc: 0.7959] 	Val:[Loss: 10.9040, Acc: 0.8768]
Epoch: 2100 	Train:[Loss: 17.9087, Acc: 0.8014] 	Val:[Loss: 10.6121, Acc: 0.8801]
Epoch: 2200 	Train:[Loss: 17.4349, Acc: 0.8066] 	Val:[Loss: 10.3251, Acc: 0.8833]
Epoch: 2300 	Train:[Loss: 16.9766, Acc: 0.8117] 	Val:[Loss: 10.0428, Acc: 0.8865]
Epoch: 2400 	Train:[Loss: 16.5326, Acc: 0.8166] 	Val:[Loss: 9.7673, Acc: 0.8896]
Epoch: 2500 	Train:[Loss: 16.1027, Acc: 0.8214] 	Val:[Loss: 9.5018, Acc: 0.8926]
Epoch: 2600 	Train:[Loss: 15.6865, Acc: 0.8260] 	Val:[Loss: 9.2491, Acc: 0.8955]
Epoch: 2700 	Train:[Loss: 15.2843, Acc: 0.8305] 	Val:[Loss: 9.0115, Acc: 0.8982]
Epoch: 2800 	Train:[Loss: 14.8954, Acc: 0.8348] 	Val:[Loss: 8.7900, Acc: 0.9007]
Epoch: 2900 	Train:[Loss: 14.5175, Acc: 0.8390] 	Val:[Loss: 8.5854, Acc: 0.9030]
Epoch: 3000 	Train:[Loss: 14.1476, Acc: 0.8431] 	Val:[Loss: 8.3983, Acc: 0.9051]
Epoch: 3100 	Train:[Loss: 13.7827, Acc: 0.8471] 	Val:[Loss: 8.2291, Acc: 0.9070]
Epoch: 3200 	Train:[Loss: 13.4204, Acc: 0.8511] 	Val:[Loss: 8.0785, Acc: 0.9087]
Epoch: 3300 	Train:[Loss: 13.0588, Acc: 0.8552] 	Val:[Loss: 7.9463, Acc: 0.9102]
Epoch: 3400 	Train:[Loss: 12.6968, Acc: 0.8592] 	Val:[Loss: 7.8327, Acc: 0.9115]
Epoch: 3500 	Train:[Loss: 12.3340, Acc: 0.8632] 	Val:[Loss: 7.7370, Acc: 0.9126]
Epoch: 3600 	Train:[Loss: 11.9704, Acc: 0.8672] 	Val:[Loss: 7.6586, Acc: 0.9134]
Epoch: 3700 	Train:[Loss: 11.6068, Acc: 0.8713] 	Val:[Loss: 7.5960, Acc: 0.9142]
Epoch: 3800 	Train:[Loss: 11.2442, Acc: 0.8753] 	Val:[Loss: 7.5475, Acc: 0.9147]
Epoch: 3900 	Train:[Loss: 10.8850, Acc: 0.8793] 	Val:[Loss: 7.5102, Acc: 0.9151]
Epoch: 4000 	Train:[Loss: 10.5329, Acc: 0.8832] 	Val:[Loss: 7.4806, Acc: 0.9155]
Epoch: 4100 	Train:[Loss: 10.1917, Acc: 0.8870] 	Val:[Loss: 7.4544, Acc: 0.9158]
Epoch: 4200 	Train:[Loss: 9.8638, Acc: 0.8906] 	Val:[Loss: 7.4278, Acc: 0.9161]
Epoch: 4300 	Train:[Loss: 9.5495, Acc: 0.8941] 	Val:[Loss: 7.3986, Acc: 0.9164]
Epoch: 4400 	Train:[Loss: 9.2483, Acc: 0.8974] 	Val:[Loss: 7.3662, Acc: 0.9168]
Epoch: 4500 	Train:[Loss: 8.9593, Acc: 0.9006] 	Val:[Loss: 7.3310, Acc: 0.9171]
Epoch: 4600 	Train:[Loss: 8.6817, Acc: 0.9037] 	Val:[Loss: 7.2942, Acc: 0.9176]
Epoch: 4700 	Train:[Loss: 8.4149, Acc: 0.9067] 	Val:[Loss: 7.2572, Acc: 0.9180]
Epoch: 4800 	Train:[Loss: 8.1586, Acc: 0.9095] 	Val:[Loss: 7.2215, Acc: 0.9184]
Epoch: 4900 	Train:[Loss: 7.9125, Acc: 0.9122] 	Val:[Loss: 7.1887, Acc: 0.9188]
Epoch: 4999 	Train:[Loss: 7.6788, Acc: 0.9148] 	Val:[Loss: 7.1602, Acc: 0.9191]
