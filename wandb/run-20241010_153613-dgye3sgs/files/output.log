Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Layer: [in:11] [out:16] [activation:Tanh]
Layer: [in:16] [out:32] [activation:Tanh]
Layer: [in:32] [out:32] [activation:Tanh]
Layer: [in:32] [out:16] [activation:Tanh]
Layer: [in:16] [out:6] [activation:Softmax]
Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:50<00:00, 59.65epoch/s, Train Acc=0.646, Val Acc=0.656]

Epoch: 0 	Train:[Loss: 6.4069, Acc: 0.1289] 	Val:[Loss: 6.0983, Acc: 0.1771]
Epoch: 256 	Train:[Loss: 1.0897, Acc: 0.5371] 	Val:[Loss: 1.0401, Acc: 0.6042]
Epoch: 512 	Train:[Loss: 1.0380, Acc: 0.5410] 	Val:[Loss: 1.0163, Acc: 0.5833]
Epoch: 768 	Train:[Loss: 1.0052, Acc: 0.5684] 	Val:[Loss: 1.0310, Acc: 0.5833]
Epoch: 1024 	Train:[Loss: 0.9584, Acc: 0.6113] 	Val:[Loss: 1.0165, Acc: 0.6146]
Epoch: 1280 	Train:[Loss: 0.9461, Acc: 0.5938] 	Val:[Loss: 1.0023, Acc: 0.6250]
Epoch: 1536 	Train:[Loss: 0.8980, Acc: 0.6270] 	Val:[Loss: 1.0261, Acc: 0.5729]
Epoch: 1792 	Train:[Loss: 0.8877, Acc: 0.6270] 	Val:[Loss: 0.9607, Acc: 0.6042]
Epoch: 2048 	Train:[Loss: 0.8672, Acc: 0.6406] 	Val:[Loss: 0.9600, Acc: 0.5938]
Epoch: 2304 	Train:[Loss: 0.8643, Acc: 0.6191] 	Val:[Loss: 0.9172, Acc: 0.6250]
Epoch: 2560 	Train:[Loss: 0.8278, Acc: 0.6543] 	Val:[Loss: 0.9947, Acc: 0.6146]
Epoch: 2816 	Train:[Loss: 0.8482, Acc: 0.6348] 	Val:[Loss: 0.9844, Acc: 0.6146]
