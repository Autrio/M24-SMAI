Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Layer: [in:11] [out:16] [activation:Tanh]
Layer: [in:16] [out:32] [activation:Tanh]
Layer: [in:32] [out:32] [activation:Tanh]
Layer: [in:32] [out:16] [activation:Tanh]
Layer: [in:16] [out:6] [activation:Softmax]
                                                                                                                                                                                                            

Epoch: 0 	Train:[Loss: 2.3449, Acc: 0.2980] 	Val:[Loss: 1.8616, Acc: 0.3750]
Epoch: 32 	Train:[Loss: 1.1185, Acc: 0.5000] 	Val:[Loss: 1.0871, Acc: 0.5417]
Epoch: 64 	Train:[Loss: 1.0742, Acc: 0.5312] 	Val:[Loss: 1.0827, Acc: 0.5625]
Epoch: 96 	Train:[Loss: 1.0487, Acc: 0.5536] 	Val:[Loss: 1.0675, Acc: 0.5729]
Epoch: 128 	Train:[Loss: 1.0235, Acc: 0.5737] 	Val:[Loss: 1.0446, Acc: 0.6042]
Epoch: 160 	Train:[Loss: 0.9982, Acc: 0.5926] 	Val:[Loss: 1.0047, Acc: 0.5938]
Epoch: 192 	Train:[Loss: 0.9761, Acc: 0.6038] 	Val:[Loss: 0.9757, Acc: 0.6042]
Epoch: 224 	Train:[Loss: 0.9623, Acc: 0.6083] 	Val:[Loss: 0.9671, Acc: 0.6042]
Epoch: 256 	Train:[Loss: 0.9521, Acc: 0.6150] 	Val:[Loss: 0.9608, Acc: 0.5938]
Epoch: 288 	Train:[Loss: 0.9499, Acc: 0.6228] 	Val:[Loss: 0.9420, Acc: 0.5625]
Epoch: 320 	Train:[Loss: 0.9274, Acc: 0.6339] 	Val:[Loss: 0.9238, Acc: 0.6042]
Epoch: 352 	Train:[Loss: 0.9126, Acc: 0.6395] 	Val:[Loss: 0.8981, Acc: 0.6250]
Epoch: 384 	Train:[Loss: 0.9009, Acc: 0.6462] 	Val:[Loss: 0.8805, Acc: 0.6562]
Epoch: 416 	Train:[Loss: 0.8918, Acc: 0.6417] 	Val:[Loss: 0.8771, Acc: 0.6667]
Epoch: 448 	Train:[Loss: 0.8840, Acc: 0.6507] 	Val:[Loss: 0.8732, Acc: 0.6458]
Epoch: 480 	Train:[Loss: 0.8729, Acc: 0.6451] 	Val:[Loss: 0.8715, Acc: 0.6875]
Epoch: 512 	Train:[Loss: 0.8677, Acc: 0.6440] 	Val:[Loss: 0.8711, Acc: 0.6875]
Epoch: 544 	Train:[Loss: 0.8562, Acc: 0.6529] 	Val:[Loss: 0.8767, Acc: 0.6875]
Epoch: 576 	Train:[Loss: 0.8569, Acc: 0.6596] 	Val:[Loss: 0.8780, Acc: 0.6667]
Epoch: 608 	Train:[Loss: 0.8450, Acc: 0.6507] 	Val:[Loss: 0.9388, Acc: 0.6562]
Epoch: 640 	Train:[Loss: 0.8324, Acc: 0.6574] 	Val:[Loss: 0.9074, Acc: 0.6771]
Epoch: 672 	Train:[Loss: 0.8242, Acc: 0.6663] 	Val:[Loss: 0.9029, Acc: 0.6875]
Epoch: 704 	Train:[Loss: 0.8189, Acc: 0.6696] 	Val:[Loss: 0.8924, Acc: 0.6562]
Epoch: 736 	Train:[Loss: 0.8142, Acc: 0.6775] 	Val:[Loss: 0.8917, Acc: 0.6771]
Epoch: 768 	Train:[Loss: 0.8107, Acc: 0.6808] 	Val:[Loss: 0.9006, Acc: 0.6562]
Epoch: 800 	Train:[Loss: 0.8061, Acc: 0.6864] 	Val:[Loss: 0.9082, Acc: 0.6562]
Epoch: 832 	Train:[Loss: 0.8018, Acc: 0.6886] 	Val:[Loss: 0.9137, Acc: 0.6562]
Epoch: 864 	Train:[Loss: 0.7967, Acc: 0.6920] 	Val:[Loss: 0.9166, Acc: 0.6562]
Epoch: 896 	Train:[Loss: 0.7917, Acc: 0.6920] 	Val:[Loss: 0.9194, Acc: 0.6667]
Epoch: 928 	Train:[Loss: 0.7859, Acc: 0.6953] 	Val:[Loss: 0.9204, Acc: 0.6562]
Epoch: 960 	Train:[Loss: 0.7797, Acc: 0.6975] 	Val:[Loss: 0.9206, Acc: 0.6771]
Epoch: 992 	Train:[Loss: 0.7734, Acc: 0.7054] 	Val:[Loss: 0.9216, Acc: 0.6875]
Epoch: 1024 	Train:[Loss: 0.7672, Acc: 0.7109] 	Val:[Loss: 0.9217, Acc: 0.6771]
Epoch: 1056 	Train:[Loss: 0.7614, Acc: 0.7132] 	Val:[Loss: 0.9215, Acc: 0.6771]
Epoch: 1088 	Train:[Loss: 0.7562, Acc: 0.7143] 	Val:[Loss: 0.9211, Acc: 0.6667]
Epoch: 1120 	Train:[Loss: 0.7566, Acc: 0.7076] 	Val:[Loss: 0.9227, Acc: 0.6354]
Epoch: 1152 	Train:[Loss: 0.7515, Acc: 0.7165] 	Val:[Loss: 0.9130, Acc: 0.6458]
Epoch: 1184 	Train:[Loss: 0.7438, Acc: 0.7199] 	Val:[Loss: 0.9154, Acc: 0.6667]
Epoch: 1216 	Train:[Loss: 0.7765, Acc: 0.6953] 	Val:[Loss: 0.9252, Acc: 0.6250]
Epoch: 1248 	Train:[Loss: 0.7425, Acc: 0.7221] 	Val:[Loss: 0.9147, Acc: 0.6667]
Epoch: 1280 	Train:[Loss: 0.7358, Acc: 0.7266] 	Val:[Loss: 0.9146, Acc: 0.6562]
Epoch: 1312 	Train:[Loss: 0.7640, Acc: 0.7009] 	Val:[Loss: 0.9228, Acc: 0.6562]
Epoch: 1344 	Train:[Loss: 0.7265, Acc: 0.7288] 	Val:[Loss: 0.9082, Acc: 0.6667]
Epoch: 1376 	Train:[Loss: 0.7256, Acc: 0.7221] 	Val:[Loss: 0.9193, Acc: 0.6771]
Epoch: 1408 	Train:[Loss: 0.7425, Acc: 0.7188] 	Val:[Loss: 0.9382, Acc: 0.6458]
Epoch: 1440 	Train:[Loss: 0.7154, Acc: 0.7277] 	Val:[Loss: 0.9259, Acc: 0.6875]
Epoch: 1472 	Train:[Loss: 0.7205, Acc: 0.7254] 	Val:[Loss: 0.9886, Acc: 0.6562]
Epoch: 1504 	Train:[Loss: 0.7354, Acc: 0.7254] 	Val:[Loss: 0.9313, Acc: 0.6562]
Epoch: 1536 	Train:[Loss: 0.7076, Acc: 0.7299] 	Val:[Loss: 0.9488, Acc: 0.6875]
Epoch: 1568 	Train:[Loss: 0.6973, Acc: 0.7388] 	Val:[Loss: 0.9820, Acc: 0.6875]
Epoch: 1600 	Train:[Loss: 0.7042, Acc: 0.7333] 	Val:[Loss: 1.0154, Acc: 0.6458]
Epoch: 1632 	Train:[Loss: 0.6947, Acc: 0.7377] 	Val:[Loss: 0.9679, Acc: 0.6667]
Epoch: 1664 	Train:[Loss: 0.6931, Acc: 0.7377] 	Val:[Loss: 0.9770, Acc: 0.6562]
Epoch: 1696 	Train:[Loss: 0.6887, Acc: 0.7467] 	Val:[Loss: 0.9775, Acc: 0.6562]
Epoch: 1728 	Train:[Loss: 0.6751, Acc: 0.7522] 	Val:[Loss: 0.9993, Acc: 0.6667]
Epoch: 1760 	Train:[Loss: 0.6685, Acc: 0.7478] 	Val:[Loss: 0.9985, Acc: 0.6354]
Epoch: 1792 	Train:[Loss: 0.7131, Acc: 0.7254] 	Val:[Loss: 0.9737, Acc: 0.6771]
Epoch: 1824 	Train:[Loss: 0.6975, Acc: 0.7422] 	Val:[Loss: 0.9920, Acc: 0.6771]
Epoch: 1856 	Train:[Loss: 0.6618, Acc: 0.7578] 	Val:[Loss: 1.0050, Acc: 0.6667]
Epoch: 1888 	Train:[Loss: 0.6561, Acc: 0.7634] 	Val:[Loss: 1.0112, Acc: 0.6458]
Epoch: 1920 	Train:[Loss: 0.6511, Acc: 0.7589] 	Val:[Loss: 1.0234, Acc: 0.6354]
Epoch: 1952 	Train:[Loss: 0.7008, Acc: 0.7400] 	Val:[Loss: 1.1255, Acc: 0.6146]
Epoch: 1984 	Train:[Loss: 0.6860, Acc: 0.7377] 	Val:[Loss: 1.0160, Acc: 0.6562]
Epoch: 2016 	Train:[Loss: 0.6402, Acc: 0.7667] 	Val:[Loss: 1.0338, Acc: 0.6458]
Epoch: 2048 	Train:[Loss: 0.6376, Acc: 0.7690] 	Val:[Loss: 1.0725, Acc: 0.6562]
Epoch: 2080 	Train:[Loss: 0.6353, Acc: 0.7779] 	Val:[Loss: 1.0293, Acc: 0.6667]
Epoch: 2112 	Train:[Loss: 0.6315, Acc: 0.7679] 	Val:[Loss: 1.0386, Acc: 0.6458]
Epoch: 2144 	Train:[Loss: 0.6364, Acc: 0.7679] 	Val:[Loss: 1.0479, Acc: 0.6354]
Epoch: 2176 	Train:[Loss: 0.6226, Acc: 0.7835] 	Val:[Loss: 1.0251, Acc: 0.6562]
Epoch: 2208 	Train:[Loss: 0.6347, Acc: 0.7656] 	Val:[Loss: 0.9976, Acc: 0.6771]
Epoch: 2240 	Train:[Loss: 0.6256, Acc: 0.7712] 	Val:[Loss: 1.0481, Acc: 0.6458]
Epoch: 2272 	Train:[Loss: 0.6282, Acc: 0.7623] 	Val:[Loss: 0.9832, Acc: 0.6562]
Epoch: 2304 	Train:[Loss: 0.6232, Acc: 0.7667] 	Val:[Loss: 1.0207, Acc: 0.6354]
Epoch: 2336 	Train:[Loss: 0.6104, Acc: 0.7846] 	Val:[Loss: 1.0458, Acc: 0.6146]
Epoch: 2368 	Train:[Loss: 0.6069, Acc: 0.7835] 	Val:[Loss: 1.0227, Acc: 0.6667]
Epoch: 2400 	Train:[Loss: 0.6013, Acc: 0.7868] 	Val:[Loss: 1.0646, Acc: 0.6042]
Epoch: 2432 	Train:[Loss: 0.5955, Acc: 0.7846] 	Val:[Loss: 1.0741, Acc: 0.6042]
Epoch: 2464 	Train:[Loss: 0.6007, Acc: 0.7768] 	Val:[Loss: 1.0552, Acc: 0.6354]
Epoch: 2496 	Train:[Loss: 0.5965, Acc: 0.7846] 	Val:[Loss: 1.0935, Acc: 0.6458]
Epoch: 2528 	Train:[Loss: 0.5969, Acc: 0.7824] 	Val:[Loss: 1.0964, Acc: 0.6458]
Epoch: 2560 	Train:[Loss: 0.5845, Acc: 0.7846] 	Val:[Loss: 1.1006, Acc: 0.6458]
Epoch: 2592 	Train:[Loss: 0.6393, Acc: 0.7623] 	Val:[Loss: 1.0927, Acc: 0.6562]
Epoch: 2624 	Train:[Loss: 0.6187, Acc: 0.7634] 	Val:[Loss: 1.0919, Acc: 0.6250]
Epoch: 2656 	Train:[Loss: 0.5762, Acc: 0.7857] 	Val:[Loss: 1.1102, Acc: 0.6354]
Epoch: 2688 	Train:[Loss: 0.6318, Acc: 0.7656] 	Val:[Loss: 1.0642, Acc: 0.6458]
Epoch: 2720 	Train:[Loss: 0.5821, Acc: 0.7824] 	Val:[Loss: 1.0892, Acc: 0.6354]
Epoch: 2752 	Train:[Loss: 0.6998, Acc: 0.7333] 	Val:[Loss: 1.1421, Acc: 0.5833]
Epoch: 2784 	Train:[Loss: 0.5626, Acc: 0.7924] 	Val:[Loss: 1.1337, Acc: 0.6458]
Epoch: 2816 	Train:[Loss: 0.6195, Acc: 0.7667] 	Val:[Loss: 1.0849, Acc: 0.6250]
Epoch: 2848 	Train:[Loss: 0.5565, Acc: 0.7958] 	Val:[Loss: 1.1239, Acc: 0.6354]
Epoch: 2880 	Train:[Loss: 0.5536, Acc: 0.7991] 	Val:[Loss: 1.1273, Acc: 0.6354]
Epoch: 2912 	Train:[Loss: 0.5628, Acc: 0.7790] 	Val:[Loss: 1.1531, Acc: 0.6250]
Epoch: 2944 	Train:[Loss: 0.5552, Acc: 0.7913] 	Val:[Loss: 1.1529, Acc: 0.6250]
Epoch: 2976 	Train:[Loss: 0.5723, Acc: 0.7835] 	Val:[Loss: 1.0514, Acc: 0.6667]
Epoch: 3008 	Train:[Loss: 0.6048, Acc: 0.7679] 	Val:[Loss: 1.1641, Acc: 0.6354]
Epoch: 3040 	Train:[Loss: 0.5386, Acc: 0.8047] 	Val:[Loss: 1.1550, Acc: 0.6250]
Epoch: 3072 	Train:[Loss: 0.5866, Acc: 0.7790] 	Val:[Loss: 1.1255, Acc: 0.6562]
Epoch: 3104 	Train:[Loss: 0.5371, Acc: 0.8002] 	Val:[Loss: 1.1397, Acc: 0.6562]
Epoch: 3136 	Train:[Loss: 0.5229, Acc: 0.8147] 	Val:[Loss: 1.1460, Acc: 0.6354]
Epoch: 3168 	Train:[Loss: 0.5183, Acc: 0.8147] 	Val:[Loss: 1.1557, Acc: 0.6667]
Epoch: 3200 	Train:[Loss: 0.5416, Acc: 0.8036] 	Val:[Loss: 1.1445, Acc: 0.6562]
Epoch: 3232 	Train:[Loss: 0.5132, Acc: 0.8192] 	Val:[Loss: 1.1586, Acc: 0.6562]
Epoch: 3264 	Train:[Loss: 0.6509, Acc: 0.7667] 	Val:[Loss: 1.1388, Acc: 0.6354]
Epoch: 3296 	Train:[Loss: 0.7222, Acc: 0.7277] 	Val:[Loss: 1.1398, Acc: 0.6667]
Epoch: 3328 	Train:[Loss: 0.5786, Acc: 0.7801] 	Val:[Loss: 1.1476, Acc: 0.6875]
Epoch: 3360 	Train:[Loss: 0.4983, Acc: 0.8170] 	Val:[Loss: 1.1900, Acc: 0.6562]
Epoch: 3392 	Train:[Loss: 0.4940, Acc: 0.8203] 	Val:[Loss: 1.2222, Acc: 0.6562]
Epoch: 3424 	Train:[Loss: 0.5683, Acc: 0.7835] 	Val:[Loss: 1.1799, Acc: 0.6667]
Epoch: 3456 	Train:[Loss: 0.5613, Acc: 0.7757] 	Val:[Loss: 1.2142, Acc: 0.6771]
Epoch: 3488 	Train:[Loss: 0.4881, Acc: 0.8158] 	Val:[Loss: 1.2178, Acc: 0.6562]
Epoch: 3520 	Train:[Loss: 0.6036, Acc: 0.7734] 	Val:[Loss: 1.1583, Acc: 0.6562]
Epoch: 3552 	Train:[Loss: 0.4968, Acc: 0.8181] 	Val:[Loss: 1.2216, Acc: 0.6354]
Epoch: 3584 	Train:[Loss: 0.7063, Acc: 0.7533] 	Val:[Loss: 1.1597, Acc: 0.6042]
Epoch: 3616 	Train:[Loss: 0.4760, Acc: 0.8248] 	Val:[Loss: 1.2378, Acc: 0.6667]
Epoch: 3648 	Train:[Loss: 0.4676, Acc: 0.8326] 	Val:[Loss: 1.2682, Acc: 0.6875]
Epoch: 3680 	Train:[Loss: 0.4702, Acc: 0.8259] 	Val:[Loss: 1.2492, Acc: 0.6562]
Epoch: 3712 	Train:[Loss: 0.6489, Acc: 0.7467] 	Val:[Loss: 1.3394, Acc: 0.6562]
Epoch: 3744 	Train:[Loss: 0.5551, Acc: 0.7790] 	Val:[Loss: 1.3387, Acc: 0.6667]
Epoch: 3776 	Train:[Loss: 0.4634, Acc: 0.8281] 	Val:[Loss: 1.2576, Acc: 0.6875]
Epoch: 3808 	Train:[Loss: 0.4609, Acc: 0.8337] 	Val:[Loss: 1.2445, Acc: 0.6979]
Epoch: 3840 	Train:[Loss: 0.4636, Acc: 0.8359] 	Val:[Loss: 1.2479, Acc: 0.7083]
Epoch: 3872 	Train:[Loss: 0.4459, Acc: 0.8438] 	Val:[Loss: 1.2683, Acc: 0.6875]
Epoch: 3904 	Train:[Loss: 0.4735, Acc: 0.8170] 	Val:[Loss: 1.2325, Acc: 0.6875]
Epoch: 3936 	Train:[Loss: 0.4402, Acc: 0.8482] 	Val:[Loss: 1.2733, Acc: 0.6875]
Epoch: 3968 	Train:[Loss: 0.5419, Acc: 0.7935] 	Val:[Loss: 1.2313, Acc: 0.6562]
Epoch: 4000 	Train:[Loss: 0.6281, Acc: 0.7667] 	Val:[Loss: 1.2081, Acc: 0.6354]
Epoch: 4032 	Train:[Loss: 0.5465, Acc: 0.7790] 	Val:[Loss: 1.2377, Acc: 0.6771]
Epoch: 4064 	Train:[Loss: 0.4271, Acc: 0.8538] 	Val:[Loss: 1.2716, Acc: 0.6875]
Epoch: 4096 	Train:[Loss: 0.5935, Acc: 0.7511] 	Val:[Loss: 1.2310, Acc: 0.6667]
Epoch: 4128 	Train:[Loss: 0.5470, Acc: 0.7969] 	Val:[Loss: 1.2293, Acc: 0.6771]
Epoch: 4160 	Train:[Loss: 0.5698, Acc: 0.7801] 	Val:[Loss: 1.1968, Acc: 0.6771]
Epoch: 4192 	Train:[Loss: 0.4575, Acc: 0.8292] 	Val:[Loss: 1.2000, Acc: 0.6771]
Epoch: 4224 	Train:[Loss: 0.6228, Acc: 0.7746] 	Val:[Loss: 1.3349, Acc: 0.6250]
Epoch: 4256 	Train:[Loss: 0.4692, Acc: 0.8225] 	Val:[Loss: 1.2771, Acc: 0.6562]
Epoch: 4288 	Train:[Loss: 0.4691, Acc: 0.8125] 	Val:[Loss: 1.2853, Acc: 0.6354]
Epoch: 4320 	Train:[Loss: 0.4875, Acc: 0.8170] 	Val:[Loss: 1.2817, Acc: 0.6562]
Epoch: 4352 	Train:[Loss: 0.4488, Acc: 0.8438] 	Val:[Loss: 1.2528, Acc: 0.6979]
Epoch: 4384 	Train:[Loss: 0.4084, Acc: 0.8571] 	Val:[Loss: 1.3191, Acc: 0.6250]
Epoch: 4416 	Train:[Loss: 0.4049, Acc: 0.8594] 	Val:[Loss: 1.3293, Acc: 0.6250]
Epoch: 4448 	Train:[Loss: 0.4727, Acc: 0.8259] 	Val:[Loss: 1.2927, Acc: 0.6250]
Epoch: 4480 	Train:[Loss: 0.4080, Acc: 0.8616] 	Val:[Loss: 1.2933, Acc: 0.6458]
Epoch: 4512 	Train:[Loss: 0.4069, Acc: 0.8650] 	Val:[Loss: 1.3192, Acc: 0.6146]
Epoch: 4544 	Train:[Loss: 0.4161, Acc: 0.8560] 	Val:[Loss: 1.3139, Acc: 0.6146]
Epoch: 4576 	Train:[Loss: 0.4091, Acc: 0.8583] 	Val:[Loss: 1.3271, Acc: 0.6250]
Epoch: 4608 	Train:[Loss: 0.4810, Acc: 0.8203] 	Val:[Loss: 1.3218, Acc: 0.6562]
Epoch: 4640 	Train:[Loss: 0.4611, Acc: 0.8292] 	Val:[Loss: 1.3729, Acc: 0.6146]
Epoch: 4672 	Train:[Loss: 0.4688, Acc: 0.8259] 	Val:[Loss: 1.4121, Acc: 0.6458]
Epoch: 4704 	Train:[Loss: 0.5831, Acc: 0.7812] 	Val:[Loss: 1.3473, Acc: 0.6250]
Epoch: 4736 	Train:[Loss: 0.3788, Acc: 0.8795] 	Val:[Loss: 1.4371, Acc: 0.6354]
Epoch: 4768 	Train:[Loss: 0.5731, Acc: 0.7757] 	Val:[Loss: 1.3084, Acc: 0.6667]
Epoch: 4800 	Train:[Loss: 0.4604, Acc: 0.8337] 	Val:[Loss: 1.3122, Acc: 0.6562]
Epoch: 4832 	Train:[Loss: 0.4488, Acc: 0.8315] 	Val:[Loss: 1.3095, Acc: 0.6667]
Epoch: 4864 	Train:[Loss: 0.4312, Acc: 0.8460] 	Val:[Loss: 1.4215, Acc: 0.6250]
Epoch: 4896 	Train:[Loss: 0.7271, Acc: 0.7511] 	Val:[Loss: 1.3725, Acc: 0.5833]
Epoch: 4928 	Train:[Loss: 0.3646, Acc: 0.8817] 	Val:[Loss: 1.4488, Acc: 0.6354]
Epoch: 4960 	Train:[Loss: 0.4617, Acc: 0.8359] 	Val:[Loss: 1.4530, Acc: 0.6250]
Epoch: 4992 	Train:[Loss: 0.3663, Acc: 0.8806] 	Val:[Loss: 1.4678, Acc: 0.6354]
