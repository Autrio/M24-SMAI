(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
Layer: [in:13] [out:16] [activation:Sigmoid]
Layer: [in:16] [out:64] [activation:Sigmoid]
Layer: [in:64] [out:128] [activation:Sigmoid]
Layer: [in:128] [out:256] [activation:Sigmoid]
Layer: [in:256] [out:1] [activation:Linear]
Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:44<00:00,  9.53epoch/s, Train Acc=0.349, Val Acc=0.446]

Epoch: 0 	Train:[Loss: 627.7685, Acc: -5.9631] 	Val:[Loss: 453.2819, Acc: -4.1227]
Epoch: 100 	Train:[Loss: 89.7211, Acc: 0.0048] 	Val:[Loss: 88.0518, Acc: 0.0049]
Epoch: 200 	Train:[Loss: 89.1877, Acc: 0.0107] 	Val:[Loss: 87.3588, Acc: 0.0127]
Epoch: 300 	Train:[Loss: 88.5615, Acc: 0.0177] 	Val:[Loss: 86.5459, Acc: 0.0219]
Epoch: 400 	Train:[Loss: 87.7526, Acc: 0.0267] 	Val:[Loss: 85.5001, Acc: 0.0337]
Epoch: 500 	Train:[Loss: 86.6160, Acc: 0.0393] 	Val:[Loss: 84.0403, Acc: 0.0502]
Epoch: 600 	Train:[Loss: 84.8929, Acc: 0.0584] 	Val:[Loss: 81.8460, Acc: 0.0750]
Epoch: 700 	Train:[Loss: 82.0952, Acc: 0.0894] 	Val:[Loss: 78.3172, Acc: 0.1149]
Epoch: 800 	Train:[Loss: 77.3283, Acc: 0.1423] 	Val:[Loss: 72.3578, Acc: 0.1823]
Epoch: 900 	Train:[Loss: 69.3856, Acc: 0.2304] 	Val:[Loss: 62.4719, Acc: 0.2940]
Epoch: 999 	Train:[Loss: 58.6978, Acc: 0.3489] 	Val:[Loss: 49.0375, Acc: 0.4458]
