Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Training:   0%|                                                                                                                                                                 | 0/1000 [00:00<?, ?epoch/s]/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:229: RuntimeWarning: overflow encountered in exp
  return (np.exp(x)/np.sum(np.exp(x), axis=-1, keepdims=True))
/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:229: RuntimeWarning: invalid value encountered in divide
  return (np.exp(x)/np.sum(np.exp(x), axis=-1, keepdims=True))
/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:252: RuntimeWarning: divide by zero encountered in log
  return np.mean(np.sum(-y  * np.log(y_pred), axis=-1))
/home/autrio/college-linx/SMAI/smai-m24-assignments-Autrio/models/MLP/MLP2.py:252: RuntimeWarning: invalid value encountered in multiply
  return np.mean(np.sum(-y  * np.log(y_pred), axis=-1))
                                                                                                                                                                                                            
Epoch: 0 	Train:[Loss: nan, Acc: 0.0379] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 32 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 64 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 96 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 128 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 160 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 192 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 224 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 256 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 288 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 320 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 352 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 384 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 416 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 448 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 480 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 512 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 544 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 576 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 608 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 640 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 672 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 704 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 736 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 768 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 800 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 832 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 864 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 896 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 928 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 960 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
Epoch: 992 	Train:[Loss: nan, Acc: 0.0067] 	Val:[Loss: nan, Acc: 0.0000]
