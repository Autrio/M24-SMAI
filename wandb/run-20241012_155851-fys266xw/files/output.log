(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
Layer: [in:13] [out:16] [activation:Sigmoid]
Layer: [in:16] [out:64] [activation:Sigmoid]
Layer: [in:64] [out:128] [activation:Sigmoid]
Layer: [in:128] [out:256] [activation:Sigmoid]
Layer: [in:256] [out:1] [activation:Linear]
Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [05:47<00:00,  5.75epoch/s, Train Acc=0.797, Val Acc=0.871]

Epoch: 0 	Train:[Loss: 616.5450, Acc: -5.8386] 	Val:[Loss: 451.8989, Acc: -4.1071]
Epoch: 128 	Train:[Loss: 89.3549, Acc: 0.0089] 	Val:[Loss: 87.6110, Acc: 0.0099]
Epoch: 256 	Train:[Loss: 88.3693, Acc: 0.0198] 	Val:[Loss: 86.3220, Acc: 0.0244]
Epoch: 384 	Train:[Loss: 86.8451, Acc: 0.0367] 	Val:[Loss: 84.3575, Acc: 0.0466]
Epoch: 512 	Train:[Loss: 84.1365, Acc: 0.0668] 	Val:[Loss: 80.9226, Acc: 0.0855]
Epoch: 640 	Train:[Loss: 78.8947, Acc: 0.1249] 	Val:[Loss: 74.3767, Acc: 0.1594]
Epoch: 768 	Train:[Loss: 69.1848, Acc: 0.2326] 	Val:[Loss: 62.3773, Acc: 0.2951]
Epoch: 896 	Train:[Loss: 56.7312, Acc: 0.3707] 	Val:[Loss: 46.8866, Acc: 0.4701]
Epoch: 1024 	Train:[Loss: 46.8359, Acc: 0.4805] 	Val:[Loss: 34.5391, Acc: 0.6097]
Epoch: 1152 	Train:[Loss: 37.0174, Acc: 0.5894] 	Val:[Loss: 23.8489, Acc: 0.7305]
Epoch: 1280 	Train:[Loss: 28.5153, Acc: 0.6837] 	Val:[Loss: 16.4943, Acc: 0.8136]
Epoch: 1408 	Train:[Loss: 24.3259, Acc: 0.7302] 	Val:[Loss: 13.7420, Acc: 0.8447]
Epoch: 1536 	Train:[Loss: 22.1168, Acc: 0.7547] 	Val:[Loss: 12.7700, Acc: 0.8557]
Epoch: 1664 	Train:[Loss: 20.6956, Acc: 0.7704] 	Val:[Loss: 12.2558, Acc: 0.8615]
Epoch: 1792 	Train:[Loss: 19.6471, Acc: 0.7821] 	Val:[Loss: 11.8868, Acc: 0.8657]
Epoch: 1920 	Train:[Loss: 18.7958, Acc: 0.7915] 	Val:[Loss: 11.5901, Acc: 0.8690]
