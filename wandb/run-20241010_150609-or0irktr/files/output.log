Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
Layer: [in:11] [out:16] [activation:Softmax]
Layer: [in:16] [out:64] [activation:Softmax]
Layer: [in:64] [out:128] [activation:Softmax]
Layer: [in:128] [out:256] [activation:Softmax]
Layer: [in:256] [out:6] [activation:Softmax]
                                                                                                                                                                                                            

Epoch: 0 	Train:[Loss: 1.7412, Acc: 0.2042] 	Val:[Loss: 1.5163, Acc: 0.3958]
Epoch: 32 	Train:[Loss: 1.1948, Acc: 0.4263] 	Val:[Loss: 1.1580, Acc: 0.4375]
Epoch: 64 	Train:[Loss: 1.1934, Acc: 0.4263] 	Val:[Loss: 1.1541, Acc: 0.4375]
Epoch: 96 	Train:[Loss: 1.1933, Acc: 0.4263] 	Val:[Loss: 1.1529, Acc: 0.4375]
Epoch: 128 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1524, Acc: 0.4375]
Epoch: 160 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1522, Acc: 0.4375]
Epoch: 192 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1521, Acc: 0.4375]
Epoch: 224 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1520, Acc: 0.4375]
Epoch: 256 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1520, Acc: 0.4375]
Epoch: 288 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 320 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 352 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 384 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 416 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 448 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 480 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 512 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 544 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 576 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 608 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 640 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 672 	Train:[Loss: 1.1932, Acc: 0.4263] 	Val:[Loss: 1.1519, Acc: 0.4375]
Epoch: 704 	Train:[Loss: 1.1915, Acc: 0.4319] 	Val:[Loss: 1.1461, Acc: 0.4479]
Epoch: 736 	Train:[Loss: 1.1910, Acc: 0.4319] 	Val:[Loss: 1.1454, Acc: 0.4479]
Epoch: 768 	Train:[Loss: 1.1906, Acc: 0.4319] 	Val:[Loss: 1.1450, Acc: 0.4479]
Epoch: 800 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1447, Acc: 0.4479]
Epoch: 832 	Train:[Loss: 1.1902, Acc: 0.4319] 	Val:[Loss: 1.1445, Acc: 0.4479]
Epoch: 864 	Train:[Loss: 1.1901, Acc: 0.4319] 	Val:[Loss: 1.1444, Acc: 0.4479]
Epoch: 896 	Train:[Loss: 1.1900, Acc: 0.4319] 	Val:[Loss: 1.1442, Acc: 0.4479]
Epoch: 928 	Train:[Loss: 1.1899, Acc: 0.4319] 	Val:[Loss: 1.1441, Acc: 0.4479]
Epoch: 960 	Train:[Loss: 1.1899, Acc: 0.4319] 	Val:[Loss: 1.1440, Acc: 0.4479]
Epoch: 992 	Train:[Loss: 1.1898, Acc: 0.4319] 	Val:[Loss: 1.1440, Acc: 0.4479]
Epoch: 1024 	Train:[Loss: 1.1898, Acc: 0.4319] 	Val:[Loss: 1.1439, Acc: 0.4479]
Epoch: 1056 	Train:[Loss: 1.1898, Acc: 0.4319] 	Val:[Loss: 1.1438, Acc: 0.4479]
Epoch: 1088 	Train:[Loss: 1.1897, Acc: 0.4319] 	Val:[Loss: 1.1437, Acc: 0.4479]
Epoch: 1120 	Train:[Loss: 1.1897, Acc: 0.4319] 	Val:[Loss: 1.1436, Acc: 0.4479]
Epoch: 1152 	Train:[Loss: 1.1897, Acc: 0.4319] 	Val:[Loss: 1.1435, Acc: 0.4479]
Epoch: 1184 	Train:[Loss: 1.1905, Acc: 0.4319] 	Val:[Loss: 1.1433, Acc: 0.4479]
Epoch: 1216 	Train:[Loss: 1.1905, Acc: 0.4319] 	Val:[Loss: 1.1430, Acc: 0.4479]
Epoch: 1248 	Train:[Loss: 1.1905, Acc: 0.4319] 	Val:[Loss: 1.1428, Acc: 0.4479]
Epoch: 1280 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1426, Acc: 0.4479]
Epoch: 1312 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1424, Acc: 0.4479]
Epoch: 1344 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1422, Acc: 0.4479]
Epoch: 1376 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1421, Acc: 0.4479]
Epoch: 1408 	Train:[Loss: 1.1911, Acc: 0.4319] 	Val:[Loss: 1.1419, Acc: 0.4479]
Epoch: 1440 	Train:[Loss: 1.1910, Acc: 0.4319] 	Val:[Loss: 1.1416, Acc: 0.4479]
Epoch: 1472 	Train:[Loss: 1.1910, Acc: 0.4319] 	Val:[Loss: 1.1414, Acc: 0.4479]
Epoch: 1504 	Train:[Loss: 1.1910, Acc: 0.4319] 	Val:[Loss: 1.1411, Acc: 0.4479]
Epoch: 1536 	Train:[Loss: 1.1909, Acc: 0.4319] 	Val:[Loss: 1.1409, Acc: 0.4479]
Epoch: 1568 	Train:[Loss: 1.1909, Acc: 0.4319] 	Val:[Loss: 1.1407, Acc: 0.4479]
Epoch: 1600 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1405, Acc: 0.4479]
Epoch: 1632 	Train:[Loss: 1.1904, Acc: 0.4319] 	Val:[Loss: 1.1405, Acc: 0.4479]
Epoch: 1664 	Train:[Loss: 1.1909, Acc: 0.4319] 	Val:[Loss: 1.1404, Acc: 0.4479]
Epoch: 1696 	Train:[Loss: 1.1909, Acc: 0.4319] 	Val:[Loss: 1.1402, Acc: 0.4479]
Epoch: 1728 	Train:[Loss: 1.1909, Acc: 0.4319] 	Val:[Loss: 1.1401, Acc: 0.4479]
Epoch: 1760 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1399, Acc: 0.4479]
Epoch: 1792 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1398, Acc: 0.4479]
Epoch: 1824 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1397, Acc: 0.4479]
Epoch: 1856 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1396, Acc: 0.4479]
Epoch: 1888 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1394, Acc: 0.4479]
Epoch: 1920 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1393, Acc: 0.4479]
Epoch: 1952 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1392, Acc: 0.4479]
Epoch: 1984 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1392, Acc: 0.4479]
Epoch: 2016 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1391, Acc: 0.4479]
Epoch: 2048 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1390, Acc: 0.4479]
Epoch: 2080 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1389, Acc: 0.4479]
Epoch: 2112 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1388, Acc: 0.4479]
Epoch: 2144 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1388, Acc: 0.4479]
Epoch: 2176 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1387, Acc: 0.4479]
Epoch: 2208 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1386, Acc: 0.4479]
Epoch: 2240 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1386, Acc: 0.4479]
Epoch: 2272 	Train:[Loss: 1.1908, Acc: 0.4319] 	Val:[Loss: 1.1385, Acc: 0.4479]
Epoch: 2304 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1384, Acc: 0.4479]
Epoch: 2336 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1384, Acc: 0.4479]
Epoch: 2368 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1383, Acc: 0.4479]
Epoch: 2400 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1383, Acc: 0.4479]
Epoch: 2432 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1382, Acc: 0.4479]
Epoch: 2464 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1382, Acc: 0.4479]
Epoch: 2496 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1381, Acc: 0.4479]
Epoch: 2528 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1381, Acc: 0.4479]
Epoch: 2560 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1380, Acc: 0.4479]
Epoch: 2592 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1380, Acc: 0.4479]
Epoch: 2624 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1380, Acc: 0.4479]
Epoch: 2656 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1379, Acc: 0.4479]
Epoch: 2688 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1379, Acc: 0.4479]
Epoch: 2720 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1378, Acc: 0.4479]
Epoch: 2752 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1378, Acc: 0.4479]
Epoch: 2784 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1378, Acc: 0.4479]
Epoch: 2816 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1377, Acc: 0.4479]
Epoch: 2848 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1377, Acc: 0.4479]
Epoch: 2880 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1377, Acc: 0.4479]
Epoch: 2912 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1377, Acc: 0.4479]
Epoch: 2944 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1376, Acc: 0.4479]
Epoch: 2976 	Train:[Loss: 1.1907, Acc: 0.4319] 	Val:[Loss: 1.1376, Acc: 0.4479]
