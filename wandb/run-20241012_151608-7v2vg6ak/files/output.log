(506,)
(506, 13)
Data split into training (406 samples), validation (50 samples), and testing (50 samples) sets.
Number of classes: 1
Feature data normalized using z-score normalization.
Layer: [in:13] [out:32] [activation:Tanh]
Layer: [in:32] [out:128] [activation:Tanh]
Layer: [in:128] [out:128] [activation:Tanh]
Layer: [in:128] [out:32] [activation:Tanh]
Layer: [in:32] [out:1] [activation:Linear]
Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:09<00:00, 15.43epoch/s, Train Acc=0.993, Val Acc=0.865]

Epoch: 0 	Train:[Loss: 607.0816, Acc: -5.7337] 	Val:[Loss: 534.4687, Acc: -5.0402]
Epoch: 128 	Train:[Loss: 33.3615, Acc: 0.6300] 	Val:[Loss: 37.1625, Acc: 0.5800]
Epoch: 256 	Train:[Loss: 14.8545, Acc: 0.8352] 	Val:[Loss: 19.0236, Acc: 0.7850]
Epoch: 384 	Train:[Loss: 8.2166, Acc: 0.9089] 	Val:[Loss: 15.0356, Acc: 0.8301]
Epoch: 512 	Train:[Loss: 5.2169, Acc: 0.9421] 	Val:[Loss: 12.9713, Acc: 0.8534]
Epoch: 640 	Train:[Loss: 15.8364, Acc: 0.8243] 	Val:[Loss: 30.4074, Acc: 0.6564]
Epoch: 768 	Train:[Loss: 2.6117, Acc: 0.9710] 	Val:[Loss: 10.6353, Acc: 0.8798]
Epoch: 896 	Train:[Loss: 2.3880, Acc: 0.9735] 	Val:[Loss: 10.2800, Acc: 0.8838]
Epoch: 1024 	Train:[Loss: 2.0421, Acc: 0.9773] 	Val:[Loss: 9.9922, Acc: 0.8871]
Epoch: 1152 	Train:[Loss: 1.5773, Acc: 0.9825] 	Val:[Loss: 9.8867, Acc: 0.8883]
Epoch: 1280 	Train:[Loss: 1.3300, Acc: 0.9852] 	Val:[Loss: 9.9509, Acc: 0.8875]
Epoch: 1408 	Train:[Loss: 1.1423, Acc: 0.9873] 	Val:[Loss: 10.0636, Acc: 0.8863]
Epoch: 1536 	Train:[Loss: 0.9876, Acc: 0.9890] 	Val:[Loss: 10.1982, Acc: 0.8847]
Epoch: 1664 	Train:[Loss: 0.8579, Acc: 0.9905] 	Val:[Loss: 10.3416, Acc: 0.8831]
Epoch: 1792 	Train:[Loss: 0.7479, Acc: 0.9917] 	Val:[Loss: 10.4909, Acc: 0.8814]
Epoch: 1920 	Train:[Loss: 0.6540, Acc: 0.9927] 	Val:[Loss: 10.6475, Acc: 0.8797]
