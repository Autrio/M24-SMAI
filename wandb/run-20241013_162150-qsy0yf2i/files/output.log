Index(['age', 'gender', 'income', 'education', 'married', 'children', 'city',
       'occupation', 'purchase_amount', 'most bought item', 'labels'],
      dtype='object')
(1000, 8)
(1000, 10)
Data split into training (800 samples), validation (100 samples), and testing (100 samples) sets.
Number of classes: 8
Feature data normalized using z-score normalization.
                                                                                                                                                                                                            
Epoch: 0 	Train:[Loss: 0.7274, Acc: 0.5247] 	Val:[Loss: 0.6945, Acc: 0.5625]
Epoch: 100 	Train:[Loss: 0.6250, Acc: 0.6549] 	Val:[Loss: 0.6439, Acc: 0.6628]
Epoch: 200 	Train:[Loss: 0.6105, Acc: 0.6660] 	Val:[Loss: 0.6665, Acc: 0.6445]
Epoch: 300 	Train:[Loss: 0.5972, Acc: 0.6774] 	Val:[Loss: 0.6839, Acc: 0.6237]
Epoch: 400 	Train:[Loss: 0.5851, Acc: 0.6875] 	Val:[Loss: 0.6959, Acc: 0.6198]
Epoch: 500 	Train:[Loss: 0.5724, Acc: 0.7031] 	Val:[Loss: 0.7058, Acc: 0.6211]
Epoch: 600 	Train:[Loss: 0.5604, Acc: 0.7077] 	Val:[Loss: 0.7197, Acc: 0.6068]
Epoch: 700 	Train:[Loss: 0.5500, Acc: 0.7150] 	Val:[Loss: 0.7389, Acc: 0.6042]
Epoch: 800 	Train:[Loss: 0.5418, Acc: 0.7220] 	Val:[Loss: 0.7545, Acc: 0.5951]
Epoch: 900 	Train:[Loss: 0.5352, Acc: 0.7241] 	Val:[Loss: 0.7662, Acc: 0.5964]
Epoch: 1000 	Train:[Loss: 0.5297, Acc: 0.7287] 	Val:[Loss: 0.7791, Acc: 0.5885]
Epoch: 1100 	Train:[Loss: 0.5250, Acc: 0.7306] 	Val:[Loss: 0.7940, Acc: 0.5833]
Epoch: 1200 	Train:[Loss: 0.5207, Acc: 0.7354] 	Val:[Loss: 0.8095, Acc: 0.5794]
Epoch: 1300 	Train:[Loss: 0.5168, Acc: 0.7394] 	Val:[Loss: 0.8232, Acc: 0.5781]
Epoch: 1400 	Train:[Loss: 0.5133, Acc: 0.7399] 	Val:[Loss: 0.8355, Acc: 0.5768]
Epoch: 1500 	Train:[Loss: 0.5099, Acc: 0.7399] 	Val:[Loss: 0.8483, Acc: 0.5690]
Epoch: 1600 	Train:[Loss: 0.5068, Acc: 0.7441] 	Val:[Loss: 0.8611, Acc: 0.5703]
Epoch: 1700 	Train:[Loss: 0.5036, Acc: 0.7469] 	Val:[Loss: 0.8770, Acc: 0.5638]
Epoch: 1800 	Train:[Loss: 0.5003, Acc: 0.7482] 	Val:[Loss: 0.8976, Acc: 0.5586]
Epoch: 1900 	Train:[Loss: 0.4971, Acc: 0.7524] 	Val:[Loss: 0.9142, Acc: 0.5625]
Epoch: 2000 	Train:[Loss: 0.4943, Acc: 0.7554] 	Val:[Loss: 0.9258, Acc: 0.5638]
Epoch: 2100 	Train:[Loss: 0.4918, Acc: 0.7518] 	Val:[Loss: 0.9358, Acc: 0.5534]
Epoch: 2200 	Train:[Loss: 0.4897, Acc: 0.7549] 	Val:[Loss: 0.9462, Acc: 0.5508]
Epoch: 2300 	Train:[Loss: 0.4877, Acc: 0.7565] 	Val:[Loss: 0.9610, Acc: 0.5495]
Epoch: 2400 	Train:[Loss: 0.4863, Acc: 0.7570] 	Val:[Loss: 0.9758, Acc: 0.5495]
Epoch: 2500 	Train:[Loss: 0.4862, Acc: 0.7575] 	Val:[Loss: 0.9889, Acc: 0.5456]
Epoch: 2600 	Train:[Loss: 0.4862, Acc: 0.7568] 	Val:[Loss: 0.9989, Acc: 0.5482]
Epoch: 2700 	Train:[Loss: 0.4851, Acc: 0.7534] 	Val:[Loss: 1.0030, Acc: 0.5560]
Epoch: 2800 	Train:[Loss: 0.4836, Acc: 0.7546] 	Val:[Loss: 1.0162, Acc: 0.5534]
Epoch: 2900 	Train:[Loss: 0.4873, Acc: 0.7542] 	Val:[Loss: 1.0030, Acc: 0.5599]
Epoch: 3000 	Train:[Loss: 0.4860, Acc: 0.7507] 	Val:[Loss: 1.0272, Acc: 0.5586]
Epoch: 3100 	Train:[Loss: 0.4848, Acc: 0.7528] 	Val:[Loss: 1.0200, Acc: 0.5560]
Epoch: 3200 	Train:[Loss: 0.4813, Acc: 0.7559] 	Val:[Loss: 0.9974, Acc: 0.5612]
Epoch: 3300 	Train:[Loss: 0.4822, Acc: 0.7534] 	Val:[Loss: 1.0268, Acc: 0.5573]
Epoch: 3400 	Train:[Loss: 0.4864, Acc: 0.7521] 	Val:[Loss: 1.0187, Acc: 0.5690]
Epoch: 3500 	Train:[Loss: 0.4844, Acc: 0.7547] 	Val:[Loss: 1.0318, Acc: 0.5664]
Epoch: 3600 	Train:[Loss: 0.4826, Acc: 0.7505] 	Val:[Loss: 1.0205, Acc: 0.5664]
Epoch: 3700 	Train:[Loss: 0.4832, Acc: 0.7541] 	Val:[Loss: 1.0216, Acc: 0.5690]
Epoch: 3800 	Train:[Loss: 0.4790, Acc: 0.7562] 	Val:[Loss: 1.0033, Acc: 0.5651]
Epoch: 3900 	Train:[Loss: 0.4778, Acc: 0.7580] 	Val:[Loss: 1.0256, Acc: 0.5586]
Epoch: 4000 	Train:[Loss: 0.4848, Acc: 0.7547] 	Val:[Loss: 1.0150, Acc: 0.5716]
Epoch: 4100 	Train:[Loss: 0.4981, Acc: 0.7424] 	Val:[Loss: 1.0290, Acc: 0.5729]
Epoch: 4200 	Train:[Loss: 0.4837, Acc: 0.7552] 	Val:[Loss: 1.0325, Acc: 0.5755]
Epoch: 4300 	Train:[Loss: 0.4802, Acc: 0.7550] 	Val:[Loss: 1.0384, Acc: 0.5664]
Epoch: 4400 	Train:[Loss: 0.4800, Acc: 0.7555] 	Val:[Loss: 1.0522, Acc: 0.5612]
Epoch: 4500 	Train:[Loss: 0.4828, Acc: 0.7505] 	Val:[Loss: 1.0441, Acc: 0.5547]
Epoch: 4600 	Train:[Loss: 0.4803, Acc: 0.7568] 	Val:[Loss: 1.0338, Acc: 0.5612]
Epoch: 4700 	Train:[Loss: 0.4879, Acc: 0.7438] 	Val:[Loss: 1.0220, Acc: 0.5651]
Epoch: 4800 	Train:[Loss: 0.4888, Acc: 0.7515] 	Val:[Loss: 1.0243, Acc: 0.5755]
Epoch: 4900 	Train:[Loss: 0.4878, Acc: 0.7507] 	Val:[Loss: 1.0016, Acc: 0.5729]
Epoch: 4999 	Train:[Loss: 0.4732, Acc: 0.7603] 	Val:[Loss: 1.0243, Acc: 0.5703]
['beauty', 'books', 'clothing', 'electronics', 'food', 'furniture', 'home', 'sports']
[0. 1. 0. 0. 0. 0. 0. 0.]
[[0.30073489 0.68440449 0.49198459 0.35066311 0.0996591  0.27231492
  0.34808526 0.19600027]]
[[0. 1. 0. 0. 0. 0. 0. 0.]]
