Data split into training (915 samples), validation (114 samples), and testing (114 samples) sets.
Number of classes: 6
Feature data normalized using z-score normalization.
                                                                                                                                                                                                            
Epoch: 0 	Train:[Loss: 0.1723, Acc: 0.0982] 	Val:[Loss: 0.1390, Acc: 0.0104]
Epoch: 16 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1060, Acc: 0.4375]
Epoch: 32 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 48 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 64 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 80 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 96 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 112 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 128 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 144 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 160 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 176 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 192 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 208 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 224 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 240 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 256 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 272 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 288 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 304 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 320 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 336 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 352 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 368 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 384 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 400 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 416 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 432 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 448 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 464 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 480 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 496 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 512 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 528 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 544 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 560 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 576 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 592 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 608 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 624 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 640 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 656 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 672 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 688 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 704 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 720 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 736 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 752 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 768 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 784 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 800 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 816 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 832 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 848 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 864 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 880 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 896 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 912 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 928 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 944 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 960 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 976 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
Epoch: 992 	Train:[Loss: 0.1076, Acc: 0.4263] 	Val:[Loss: 0.1059, Acc: 0.4375]
